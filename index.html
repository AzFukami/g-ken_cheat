<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>G検定 最強チートシート (全解説搭載・決定版)</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;700&family=Noto+Sans+JP:wght@400;500;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', 'Noto Sans JP', sans-serif;
            -webkit-font-smoothing: antialiased;
            -moz-osx-font-smoothing: grayscale;
        }
        /* スクロールバーのスタイル */
        ::-webkit-scrollbar {
            width: 8px;
        }
        ::-webkit-scrollbar-track {
            background: #1f2937;
        }
        ::-webkit-scrollbar-thumb {
            background: #4b5563;
            border-radius: 4px;
        }
        ::-webkit-scrollbar-thumb:hover {
            background: #6b7280;
        }
        .term-description strong {
            color: #67e8f9; /* cyan-300 */
            font-weight: 600;
        }
        .term-description code {
            background-color: #374151; /* gray-700 */
            color: #f3f4f6; /* gray-100 */
            padding: 0.1em 0.3em;
            border-radius: 4px;
            font-size: 0.9em;
        }
        #detailedExplanation strong, #detailedExplanation b {
            color: #67e8f9;
        }
        #detailedExplanation ul {
            list-style-type: disc;
            margin-left: 1.5rem;
            margin-top: 0.5rem;
            margin-bottom: 0.5rem;
        }
        #detailedExplanation li {
             margin-bottom: 0.25rem;
        }
         #detailedExplanation h4 {
            font-size: 1.1rem;
            font-weight: bold;
            color: #93c5fd; /* blue-300 */
            margin-top: 1rem;
            border-bottom: 1px solid #374151;
            padding-bottom: 0.25rem;
        }
    </style>
</head>
<body class="bg-gray-900 text-gray-200">

    <div class="container mx-auto p-4 md:p-8">
        <!-- ヘッダー部分 -->
        <header class="text-center mb-8">
            <h1 class="text-3xl md:text-4xl font-bold text-cyan-400 mb-2">G検定 最強チートシート 🚀</h1>
            <p class="text-gray-400">全用語の詳細解説つき！【最終決定版】</p>
        </header>

        <!-- 検索・フィルタリング部分 -->
        <div class="sticky top-0 z-10 bg-gray-900/80 backdrop-blur-md py-4 mb-8">
            <div class="max-w-5xl mx-auto">
                <!-- 検索ボックス -->
                <input type="text" id="searchInput" placeholder="🔍  検索キーワードを入力 (例: 混合行列, Adam)" class="w-full p-3 bg-gray-800 border-2 border-gray-700 rounded-lg focus:ring-2 focus:ring-cyan-500 focus:border-cyan-500 transition-all text-white placeholder-gray-500">
                
                <!-- カテゴリフィルター -->
                <div id="categoryFilters" class="flex flex-wrap justify-center gap-2 mt-4">
                    <button class="filter-btn active" data-category="all">すべて</button>
                    <button class="filter-btn" data-category="歴史・人物">歴史・人物</button>
                    <button class="filter-btn" data-category="機械学習">機械学習</button>
                    <button class="filter-btn" data-category="ディープラーニング">ディープラーニング</button>
                    <button class="filter-btn" data-category="データサイエンス・統計">DS・統計</button>
                    <button class="filter-btn" data-category="ハードウェア・インフラ">HW・インフラ</button>
                    <button class="filter-btn" data-category="法律・倫理">法律・倫理</button>
                    <button class="filter-btn" data-category="応用分野">応用分野</button>
                </div>
            </div>
        </div>

        <!-- 用語リスト -->
        <main id="termList" class="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 xl:grid-cols-4 gap-6">
            <!-- JavaScriptによって用語カードがここに挿入されます -->
        </main>

        <!-- 項目が見つからない場合のメッセージ -->
        <div id="noResults" class="hidden text-center py-16">
            <p class="text-2xl text-gray-500">😢</p>
            <p class="text-xl text-gray-500 mt-2">該当する用語が見つかりませんでした。</p>
            <p class="text-gray-600 mt-1">検索キーワードやカテゴリを変えてみてください。</p>
        </div>

    </div>

    <!-- Modal -->
    <div id="explanationModal" class="fixed inset-0 bg-black bg-opacity-70 z-50 hidden items-center justify-center p-4 transition-opacity duration-300">
        <div class="bg-gray-800 rounded-lg shadow-2xl w-full max-w-2xl max-h-[90vh] flex flex-col transform transition-transform duration-300 scale-95">
            <header class="flex justify-between items-center p-4 border-b border-gray-700 flex-shrink-0">
                <h2 class="text-xl font-bold text-cyan-400 flex items-center gap-2">
                    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="text-cyan-400"><path d="M10 3L8 21h1l2-18-4 8 4-5-2 15h1l2-18"/></svg>
                    <span id="modalTitle">詳細解説</span>
                </h2>
                <button id="closeModalBtn" class="text-gray-400 hover:text-white text-3xl leading-none">&times;</button>
            </header>
            <div class="p-6 overflow-y-auto" id="modalContentArea">
                <!-- Response will be injected here -->
                <div id="detailedExplanation" class="text-gray-300 leading-relaxed space-y-4"></div>
            </div>
        </div>
    </div>


    <script>
        const termsData = [
            // --- 歴史・人物 ---
            { term: 'アラン・チューリング', category: '歴史・人物', description: '「計算機科学の父」「人工知能の父」と呼ばれる。機械が知的かどうかを判定する<strong>【活用例】</strong>「チューリングテスト」を提唱。第二次世界大戦中、ドイツの暗号機エニグマの解読に貢献したことでも知られる。' },
            { term: 'ジョン・マッカーシー', category: '歴史・人物', description: '1956年のダートマス会議で「人工知能(Artificial Intelligence)」という言葉を初めて使用した人物。<strong>【活用例】</strong>AI研究用のプログラミング言語LISPを開発。' },
            { term: 'マービン・ミンスキー', category: '歴史・人物', description: 'AI研究の創始者の一人。パーセプトロンの限界（線形分離不可能な問題は解けない）を指摘し、第一次AIブームの終焉に影響を与えた。<strong>【活用例】</strong>知識を表現するためのフレーム理論を提唱。' },
            { term: 'アーサー・サミュエル', category: '歴史・人物', description: '「機械学習」という言葉の生みの親とされる人物。<strong>【活用例】</strong>自身が作ったチェッカープログラムに自己学習機能を持たせ、人間以上の強さを実現した。' },
            { term: 'フランク・ローゼンブラット', category: '歴史・人物', description: 'ニューラルネットワークの源流である「パーセプトロン」を考案した心理学者・計算機科学者。' },
            { term: 'ジェフリー・ヒントン', category: '歴史・人物', description: '「ディープラーニングの父」の一人。<strong>【活用例】</strong>誤差逆伝播法の研究や、2012年の画像認識コンテストILSVRCでAlexNetを開発し圧勝。第三次AIブームの立役者。' },
            { term: 'ヤン・ルカン', category: '歴史・人物', description: '「ディープラーニングの父」の一人。畳み込みニューラルネットワーク(CNN)の生みの親。<strong>【活用例】</strong>手書き文字認識システムLeNetを開発し、銀行のATMでの手書き小切手の数字読み取りなどに活用された。' },
            { term: 'ヨシュア・ベンジオ', category: '歴史・人物', description: '「ディープラーニングの父」の一人。確率的勾配降下法や再帰型ニューラルネットワーク(RNN)の研究で知られる。' },
            { term: 'レイ・カーツワイル', category: '歴史・人物', description: '未来学者。「シンギュラリティ(技術的特異点)」を提唱し、2045年にAIが人間の知能を超えると予測していることで有名。' },
            { term: 'ジョン・サール', category: '歴史・人物', description: '「強いAI」と「弱いAI」という考え方を提唱。<strong>【活用例】</strong>コンピュータが真に知性を持つことはないとする思考実験「中国語の部屋」で知られる。' },
            { term: 'ロドニー・ブルックス', category: '歴史・人物', description: '従来の記号的AIを批判し、「包摂アーキテクチャ」という行動ベースのAIを提唱。知能は身体性を伴って環境との相互作用の中で生まれるとした。ロボット「ルンバ」の開発者としても有名。'},
            { term: 'ダートマス会議', category: '歴史・人物', description: '1956年に開催された、AI研究の出発点とされる歴史的な会議。ジョン・マッカーシーによって「人工知能」という言葉が初めて公に使われた。' },
            { term: 'AIの冬の時代', category: '歴史・人物', description: 'AI研究に対する期待が大きすぎた反動で、研究資金が打ち切られるなどした停滞期のこと。1970年代中頃〜と1980年代後半〜の2回あったとされる。' },
            { term: 'エキスパートシステム', category: '歴史・人物', description: '第二次AIブームの中心となった技術。専門家の知識をルールとしてコンピュータに組み込み、専門家のように振る舞うシステム。<strong>【活用例】</strong>医療診断支援システムMYCINなど。知識の獲得（知識のボトルネック）が課題となった。'},

            // --- 機械学習 ---
            { term: '教師あり学習', category: '機械学習', description: '正解ラベル(y)付きの入力データ(x)を使い、xからyを予測する関数f(x)を学習する手法。<strong>【技術詳細】</strong>学習時には、予測値と正解値の誤差を定義した「損失関数」（回帰では平均二乗誤差、分類では交差エントロピー誤差など）を最小化するようにモデルのパラメータを更新する。' },
            { term: '教師なし学習', category: '機械学習', description: '正解ラベルがないデータから、その背後にある構造やパターンを発見する手法。<strong>【技術詳細】</strong>クラスタリング(k-means法)、次元削減(主成分分析PCA)、アソシエーション分析(Apriori)などが代表的なアルゴリズム。' },
            { term: '強化学習', category: '機械学習', description: 'エージェントが環境内で試行錯誤し、報酬を最大化する行動方針(Policy)を学習する手法。<strong>【技術詳細】</strong>「マルコフ決定過程」として定式化される。価値関数を学習するQ学習や、方策を直接学習する方策勾配法などがある。' },
            { term: '半教師あり学習', category: '機械学習', description: '少量のラベル付きデータと大量のラベルなしデータを組み合わせて学習する手法。<strong>【技術詳細】</strong>ラベル付けのコストが高い場合に有効。ラベルなしデータでデータの分布を学習し、ラベル付きデータで精度を上げる。' },
            { term: '自己教師あり学習', category: '機械学習', description: 'データ自身から擬似的なラベルを自動生成し、それを解くタスク（Pretext Task）を学習する手法。<strong>【技術詳細】</strong>BERTのMasked LMや、画像の一部を予測させるタスクが例。大量のラベルなしデータから特徴表現を学習できるため、転移学習の事前学習で広く使われる。' },
            { term: '回帰 (Regression)', category: '機械学習', description: '連続的な数値を予測するタスク。<strong>【技術詳細】</strong>線形回帰、多項式回帰、サポートベクター回帰(SVR)などがある。評価指標は平均二乗誤差(MSE)や平均絶対誤差(MAE)が用いられる。' },
            { term: '分類 (Classification)', category: '機械学習', description: 'データがどのカテゴリに属するかを予測するタスク。<strong>【技術詳細】</strong>2値分類（ロジスティック回帰）と多クラス分類がある。評価指標は正解率、適合率、再現率、F値、AUCなどが用いられる。' },
            { term: 'ロジスティック回帰', category: '機械学習', description: '分類問題で用いられる基本的な手法。ある事象が発生する確率を予測する。<strong>【技術詳細】</strong>線形回帰の出力をシグモイド関数に通すことで、出力を0〜1の確率に変換する。線形分離可能な問題に使われる。'},
            { term: 'k-NN法 (k近傍法)', category: '機械学習', description: '分類や回帰に用いられる単純な手法。未知のデータと最も近いk個の既知のデータを見て、多数決でクラスを決定する。<strong>【技術詳細】</strong>怠惰学習（lazy learning）の一種で、学習フェーズがほぼなく、予測時に計算コストがかかる。kの値をどう設定するかが重要。'},
            { term: '過学習 (Overfitting)', category: '機械学習', description: '訓練データに適合しすぎて未知のデータへの予測精度が低い状態。<strong>【技術詳細】</strong>モデルの表現力が高すぎる（高バリアンス）か、訓練データが少ない場合に発生。訓練誤差は小さいが、テスト誤差が大きいのが特徴。「バイアスとバリアンスのトレードオフ」の観点から理解される。' },
            { term: '正則化 (Regularization)', category: '機械学習', description: '過学習を防ぐため、モデルの複雑さにペナルティを課す手法。<strong>【技術詳細】</strong>損失関数に正則化項を追加する。L1正則化(Lasso)は一部の重みを0にし特徴量選択の効果を持つ。L2正則化(Ridge)は重みが大きくなるのを防ぐ。' },
            { term: 'サポートベクターマシン (SVM)', category: '機械学習', description: 'マージン最大化という考えに基づき、高い汎化性能を持つ分類器。<strong>【技術詳細】</strong>「カーネルトリック」を用いることで、線形分離不可能なデータも高次元空間に写像して線形分離を可能にする（多項式カーネル、RBFカーネルなど）。' },
            { term: 'アンサンブル学習', category: '機械学習', description: '複数の弱学習器を組み合わせ、より強力なモデルを構築する手法。<strong>【技術詳細】</strong>代表的な手法に、並列に学習させる「バギング」（ランダムフォレスト）と、逐次的に学習させる「ブースティング」（勾配ブースティング）がある。' },
            { term: 'ハイパーパラメータ', category: '機械学習', description: '機械学習モデルの学習プロセス自体を制御するパラメータ。モデルがデータから学習するパラメータ（重みなど）とは区別される。<strong>【技術詳細】</strong>学習率、正則化の強さ、決定木の深さ、k-NNのkの値などが該当。グリッドサーチやベイジアン最適化などの手法で最適な値を探す。'},

            // --- ディープラーニング ---
            { term: 'ニューラルネットワーク', category: 'ディープラーニング', description: '脳の神経細胞を模倣した数理モデル。重み(w)とバイアス(b)を持つ多数のニューロン（ノード）が層状に結合している。<strong>【技術詳細】</strong>入力信号の重み付き和を活性化関数で非線形変換し、次の層に出力する。' },
            { term: '活性化関数', category: 'ディープラーニング', description: 'ニューロンの発火を模倣し、ネットワークに非線形性をもたらす関数。<strong>【技術詳細】</strong>初期によく使われたシグモイド関数やtanh関数は勾配消失問題を起こしやすい。現在では<code>ReLU(max(0, x))</code>が主流。出力層では、多クラス分類の確率出力にソフトマックス関数が使われる。' },
            { term: '誤差逆伝播法', category: 'ディープラーニング', description: '出力と正解の誤差を、微分係数の連鎖律(Chain Rule)を用いて、出力層から入力層へ逆方向に伝播させ、各層の重みを効率的に更新するアルゴリズム。' },
            { term: '最適化アルゴリズム (Optimizer)', category: 'ディープラーニング', description: '損失関数を最小化するために、モデルの重みを効率的に更新する手法。<strong>【技術詳細】</strong><code>SGD</code>（確率的勾配降下法）が基本。<code>Momentum</code>は慣性を加えることで収束を速める。<code>Adam</code>は各パラメータに対して適応的に学習率を調整する手法で、現在最も広く使われている。'},
            { term: '学習率 (Learning Rate)', category: 'ディープラーニング', description: '重みを更新する際のステップ幅を制御するハイパーパラメータ。<strong>【技術詳細】</strong>大きすぎると学習が発散し、小さすぎると収束が非常に遅くなる。学習率を徐々に小さくするスケジューリング手法（学習率減衰）も一般的。'},
            { term: 'ドロップアウト (Dropout)', category: 'ディープラーニング', description: '過学習を抑制するための正則化手法。<strong>【技術詳細】</strong>学習時に、各ニューロンを一定の確率でランダムに無効化（ドロップアウト）する。これにより、特定のニューロンへの過度な依存を防ぎ、アンサンブル学習に似た効果が得られる。'},
            { term: '勾配消失/爆発問題', category: 'ディープラーニング', description: '深いネットワークで誤差逆伝播を行う際、勾配が層を遡るごとに指数関数的に小さくなる（消失）か、大きくなる（爆発）問題。<strong>【技術詳細】</strong>消失すると学習が停滞し、爆発すると学習が不安定になる。ReLU、ResNet、LSTM、勾配クリッピングなどが対策として知られる。' },
            { term: 'バッチ正規化', category: 'ディープラーニング', description: 'ミニバッチ単位で、層への入力データの分布を平均0、分散1に正規化する手法。<strong>【技術詳細】</strong>各層の入力分布の変動（内部共変量シフト）を抑制し、学習の安定化・高速化、正則化の効果をもたらす。' },
            { term: 'CNN (畳み込みニューラルネットワーク)', category: 'ディープラーニング', description: '主に画像認識で使われるモデル。<strong>【技術詳細】</strong>「畳み込み層」でフィルタ（カーネル）をスライドさせ特徴マップを抽出し、「プーリング層」で特徴を圧縮する。これにより、画像の局所的な特徴と位置不変性を獲得できる。' },
            { term: 'RNN (再帰型ニューラルネットワーク)', category: 'ディープラーニング', description: '順序性のあるデータを扱うのが得意なモデル。<strong>【技術詳細】</strong>過去の情報を内部状態（隠れ状態）<code>h_t</code>として保持し、現在の入力<code>x_t</code>と過去の状態<code>h_{t-1}</code>から次の状態<code>h_t</code>を計算するループ構造を持つ。長期の依存関係の学習が苦手。' },
            { term: 'LSTM (Long Short-Term Memory)', category: 'ディープラーニング', description: 'RNNの長期依存性問題を解決するために考案されたモデル。<strong>【技術詳細】</strong>情報を忘れるか保持するかを制御する「忘却ゲート」、新しい情報を追加する「入力ゲート」、何を出力するかを制御する「出力ゲート」という3つのゲート構造を導入した。' },
            { term: 'GRU (Gated Recurrent Unit)', category: 'ディープラーニング', description: 'LSTMを簡略化したモデル。<strong>【技術詳細】</strong>更新ゲートとリセットゲートの2つのゲートのみで構成され、LSTMよりパラメータが少なく計算効率が良い。性能はタスクによるがLSTMに匹敵することも多い。'},
            { term: 'Seq2Seq', category: 'ディープラーニング', description: 'あるシーケンス（系列）を入力として、別のシーケンスを出力するモデルの総称。<strong>【技術詳細】</strong>入力系列を固定長のベクトルに変換するエンコーダと、そのベクトルから出力系列を生成するデコーダから構成される。機械翻訳や対話システムで使われる。'},
            { term: 'Transformer', category: 'ディープラーニング', description: '自然言語処理に革命をもたらしたモデル。<strong>【技術詳細】</strong>RNNの再帰構造を廃し、「自己注意機構(Self-Attention)」を用いて入力系列内の単語間の関連度を直接計算する。並列計算に優れ、GPTやBERTの基盤技術。' },
            { term: 'Attention (アテンション) 機構', category: 'ディープラーニング', description: '入力系列のどの部分に「注目」すべきかを動的に学習する仕組み。<strong>【技術詳細】</strong>Query, Key, Valueという3つのベクトルを用いて、Queryと各Keyの類似度を計算し、その重みに基づいてValueの重み付き和を求める。' },
            { term: '転移学習 (Transfer Learning)', category: 'ディープラーニング', description: 'あるタスクで学習済みのモデルを別のタスクに適用する手法。<strong>【技術詳細】</strong>ImageNetで学習済みの<code>VGG16</code>や<code>ResNet</code>、大規模テキストで学習済みの<code>BERT</code>などがベースモデルとしてよく利用される。' },
            { term: 'GAN (敵対的生成ネットワーク)', category: 'ディープラーニング', description: '生成器(G)と識別器(D)を競わせることでリアルなデータを生成するモデル。<strong>【技術詳細】</strong>Gは乱数から偽データを生成し、DはGが生成したデータか本物のデータかを見分ける。GはDを騙そうと学習し、DはGを見破ろうと学習する「ミニマックスゲーム」を行う。' },
            { term: 'オートエンコーダ', category: 'ディープラーニング', description: '教師なし学習の一種。データを圧縮するエンコーダと、復元するデコーダから成る。<strong>【技術詳細】</strong>入力データ自身を正解ラベルとして学習する。潜在空間の表現を学習でき、変分オートエンコーダ(VAE)はデータ生成にも応用される。' },
            { term: 'ResNet (Residual Network)', category: 'ディープラーニング', description: '「スキップ接続」で非常に深いネットワークの学習を可能にしたモデル。<strong>【技術詳細】</strong>層の入力が出力に直接足し合わされる「残差ブロック」を導入。これにより、ネットワークは恒等写像を学習しやすくなり、勾配消失問題が緩和され、1000層を超える学習も可能になった。' },
            { term: 'BERT', category: 'ディープラーニング', description: 'Googleが開発したTransformerベースの自然言語処理モデル。<strong>【技術詳細】</strong>事前学習タスクとして、文中の単語をマスクし予測する「Masked LM」と、2文が連続しているかを予測する「Next Sentence Prediction」を用いることで、双方向の文脈を深く理解する。' },
            { term: 'GPT (Generative Pre-trained Transformer)', category: 'ディープラーニング', description: 'OpenAIが開発した大規模言語モデル。<strong>【技術詳細】</strong>Transformerのデコーダ部分をベースにしており、膨大なテキストデータで事前学習されている。文章生成能力が非常に高く、ChatGPTの基盤技術。'},
            { term: '物体検出 (Object Detection)', category: 'ディープラーニング', description: '画像内の物体の「位置」と「種類（クラス）」を同時に特定するタスク。<strong>【技術詳細】</strong><code>Faster R-CNN</code>のような2段階検出器と、<code>YOLO</code>や<code>SSD</code>のような1段階検出器がある。自動運転や防犯カメラで重要な技術。'},
            { term: 'セマンティックセグメンテーション', category: 'ディープラーニング', description: '画像をピクセル単位で分類し、各ピクセルがどのクラスに属するかを識別するタスク。<strong>【技術詳細】</strong>エンコーダ・デコーダ構造を持つ<code>FCN</code>や<code>U-Net</code>が有名。自動運転の道路領域認識や医療画像の臓器抽出などに使われる。'},
            { term: 'モデル圧縮', category: 'ディープラーニング', description: '学習済みモデルのサイズを小さくし、推論を高速化する技術群。<strong>【技術詳細】</strong><code>量子化</code>（パラメータの精度を落とす）、<code>枝刈り（プルーニング）</code>（重要でない重みを削除）、<code>知識蒸留</code>（巨大な教師モデルの知識を小さな生徒モデルに継承）などがある。'},
            
            // --- データサイエンス・統計 ---
            { term: 'EDA (探索的データ分析)', category: 'データサイエンス・統計', description: 'データセットを様々な角度から可視化・要約し、データの構造や特徴、パターン、外れ値などを把握するプロセス。<strong>【技術詳細】</strong>ヒストグラム、散布図、箱ひげ図などのグラフ作成や、平均、中央値、相関係数などの基本統計量の計算を行う。' },
            { term: '特徴量エンジニアリング', category: 'データサイエンス・統計', description: '生のデータからモデルが学習しやすい特徴量を作成・選択・加工するプロセス。<strong>【技術詳細】</strong>ドメイン知識を活かして新しい特徴量を作成したり、カテゴリ変数をOne-Hotエンコーディングしたり、数値データを標準化・正規化したりする作業が含まれる。' },
            { term: '欠損値処理', category: 'データサイエンス・統計', description: 'データセットに含まれる値がない（欠損している）部分に対処すること。<strong>【技術詳細】</strong>欠損している行や列を削除する、平均値や中央値で補完する、機械学習モデルで予測して補完するなどの手法がある。' },
            { term: 'データ拡張 (Data Augmentation)', category: 'データサイエンス・統計', description: '既存の訓練データを人工的に水増しする技術。過学習の抑制に有効。<strong>【活用例】</strong>画像データに対して、回転、反転、拡大・縮小、明るさの変更などの処理を加え、あたかも新しいデータであるかのように見せかけて学習させる。'},
            { term: '標準化と正規化', category: 'データサイエンス・統計', description: '複数の特徴量の尺度（スケール）を揃えるための前処理。<strong>【技術詳細】</strong>標準化は平均0、分散1に変換。正規化は最小値0、最大値1の範囲に変換。距離ベースの手法（SVM、k-NNなど）で特に重要。' },
            { term: '混合行列 (Confusion Matrix)', category: 'データサイエンス・統計', description: '分類モデルの性能を評価するための表。予測が正解だったか不正解だったかを、クラスごとにまとめる。<strong>【技術詳細】</strong>True Positive (TP), False Positive (FP), True Negative (TN), False Negative (FN) の4つの値から構成される。' },
            { term: '適合率 (Precision) と 再現率 (Recall)', category: 'データサイエンス・統計', description: '分類モデルの評価指標。<strong>【技術詳細】</strong>適合率=TP/(TP+FP)で「陽性と予測した中で、実際に陽性だった割合」。再現率=TP/(TP+FN)で「実際に陽性のものを見逃さずに予測できた割合」。両者はトレードオフの関係。' },
            { term: 'F値 (F-measure)', category: 'データサイエンス・統計', description: '適合率と再現率の調和平均。両方の指標をバランス良く評価する。<strong>【技術詳細】</strong><code>2 * (Precision * Recall) / (Precision + Recall)</code> で計算される。不均衡データ（陽性例が極端に少ないなど）の評価に適している。' },
            { term: 'ROC曲線・AUC', category: 'データサイエンス・統計', description: '2値分類モデルの性能評価で用いられる指標。<strong>【技術詳細】</strong>ROC曲線は、分類の閾値を変化させたときの真陽性率（再現率）と偽陽性率の関係をプロットしたグラフ。AUCはその曲線下の面積で、1に近いほど高性能。' },
            { term: 'バイアスとバリアンス', category: 'データサイエンス・統計', description: 'モデルの予測誤差を構成する2つの要素。<strong>【技術詳細】</strong>バイアスはモデルの予測の偏り（単純すぎてデータにフィットしない）。バリアンスはデータのばらつきによる予測の不安定さ（複雑すぎてデータに過剰反応する）。両者はトレードオフの関係にある。' },
            { term: 'p値 (p-value)', category: 'データサイエンス・統計', description: '統計的仮説検定で、帰無仮説のもとで観測された結果以上に極端な結果が得られる確率。<strong>【技術詳細】</strong>慣習的にp値が0.05などの有意水準より小さい場合、帰無仮説は棄却され、対立仮説が採択される。' },
            { term: '不均衡データ (Imbalanced Data)', category: 'データサイエンス・統計', description: '分類問題で、クラス間のデータ数に大きな偏りがあるデータセット。<strong>【技術詳細】</strong>そのまま学習すると多数派クラスに偏ったモデルになりやすい。対策として、<code>オーバーサンプリング</code>(SMOTEなど)や<code>アンダーサンプリング</code>がある。'},

            // --- ハードウェア・インフラ ---
            { term: 'GPU (Graphics Processing Unit)', category: 'ハードウェア・インフラ', description: '元々は画像処理用のプロセッサだが、単純な計算を並列で大量にこなす能力に長けているため、ディープラーニングの行列演算で広く利用される。NVIDIA社が有名。'},
            { term: 'TPU (Tensor Processing Unit)', category: 'ハードウェア・インフラ', description: 'Googleがディープラーニング専用に開発したプロセッサ。行列演算に特化しており、GPUよりもさらに高速・高効率な処理が可能。Google Cloudなどで利用できる。'},
            { term: 'FPGA (Field-Programmable Gate Array)', category: 'ハードウェア・インフラ', description: '製造後に購入者が回路構成をプログラムできる集積回路。特定の処理に特化した回路を組むことで、低遅延・低消費電力を実現できる。エッジAIなどで利用される。'},
            { term: 'クラウドコンピューティング', category: 'ハードウェア・インフラ', description: 'インターネット経由で、サーバー、ストレージ、データベース、AIモデルなどのコンピューティングサービスを利用すること。<strong>【活用例】</strong>AWS、Google Cloud(GCP)、Microsoft Azureが3大クラウドとして知られ、高性能なGPUインスタンスやAI開発プラットフォームを提供している。'},
            { term: 'コンテナ技術', category: 'ハードウェア・インフラ', description: 'アプリケーションを、その実行に必要なライブラリや設定などと一緒にパッケージ化する技術。<strong>【技術詳細】</strong><code>Docker</code>が代表的。どこでも同じ環境を再現できるため、開発から本番環境への移行がスムーズになる。'},
            { term: 'Kubernetes', category: 'ハードウェア・インフラ', description: 'コンテナ化されたアプリケーションのデプロイ、スケーリング、管理を自動化するためのオープンソースシステム。コンテナオーケストレーションツールとも呼ばれる。'},
            { term: 'MLOps', category: 'ハードウェア・インフラ', description: '機械学習(ML)と運用(Operations)を組み合わせた造語。機械学習モデルの開発から運用、再学習までのライフサイクルを効率的に管理・自動化するためのプラクティス。'},

            // --- 法律・倫理 ---
            { term: '個人情報保護法', category: '法律・倫理', description: '個人の権利利益を保護することを目的とした法律。<strong>【具体例】</strong>AIチャットボットに顧客が入力した氏名や住所を、本人の同意なくマーケティングに利用することは違法となる。' },
            { term: '著作権法', category: '法律・倫理', description: '著作物と著作者の権利を保護する法律。<strong>【具体例】</strong>インターネット上のイラストを無断で大量に学習データとして利用し、作風を模倣した画像を生成するAIサービスは、著作権侵害となる可能性がある。' },
            { term: 'GDPR (一般データ保護規則)', category: '法律・倫理', description: 'EUにおける個人のデータ保護とプライバシーに関する包括的な法律。<strong>【具体例】</strong>日本の企業がEU居住者向けにサービスを提供する場合、Cookie利用の同意を明確に取得したり、ユーザーからのデータ削除要求に応じたりする必要がある。' },
            { term: 'AI開発原則', category: '法律・倫理', description: '内閣府が示した、AI開発者が遵守すべき原則。「人間の尊厳」「多様性・公平性」「プライバシーの確保」「セキュリティ」「透明性」などが含まれる。' },
            { term: '説明可能なAI (XAI)', category: '法律・倫理', description: 'AIの判断根拠を人間が理解・解釈できるようにするための技術。<strong>【技術詳細】</strong>判断に寄与した特徴量を可視化するLIMEやSHAP、CNNの判断根拠を可視化するGrad-CAMなどの手法がある。' },
            { term: 'アルゴリズムの公平性 / バイアス', category: '法律・倫理', description: 'AIモデルが、特定の属性に基づいて不公平な判断を下してしまう問題。<strong>【具体例】</strong>過去の採用データに男性が多いという偏りがあった場合、それを学習したAIが男性を優先的に採用してしまう「ジェンダーバイアス」。' },
            { term: 'フレーム問題', category: '法律・倫理', description: 'AIにおける重要な哲学的問題。「ある行動を実行する際に、考慮すべき有限の事柄と、無関係で考慮しなくてよい事柄を、どうやって限定するのか」という問題。'},
            { term: 'シンボルグラウンディング問題', category: '法律・倫理', description: 'AIが扱う記号（シンボル）が、実世界の意味とどのように結びついているのか（接地しているのか）という問題。記号処理だけでは真の知能とは言えないという批判。'},
            { term: 'ディープフェイク', category: '法律・倫理', description: 'ディープラーニングを用いて、人物の顔や声を本物そっくりに合成した偽の動画や音声。<strong>【技術詳細】</strong>主にGANの技術が利用されている。' },
            { term: 'トロリー問題', category: '法律・倫理', description: '倫理学における思考実験。<strong>【具体例】</strong>自動運転車が事故を避けられない状況で、「歩行者一人を犠牲にするか、乗員が犠牲になるか」といったAIの倫理的な意思決定の難しさを示す例として挙げられる。' },
            
            // --- 応用分野 ---
            { term: '自然言語処理 (NLP)', category: '応用分野', description: '人間が日常的に使う言葉（自然言語）をコンピュータが処理・理解するための技術分野。<strong>【活用例】</strong>SiriやGoogleアシスタント、機械翻訳のDeepL、文法チェックツールのGrammarlyなど。' },
            { term: '画像認識', category: '応用分野', description: '画像や動画の中から、特定の物体、人物、風景などを識別・検出する技術。<strong>【活用例】</strong>Facebookの写真の自動タグ付け、空港の顔認証ゲート、自動車のナンバープレート読み取りシステム。' },
            { term: '音声認識', category: '応用分野', description: '人間が発する音声・話し言葉をコンピュータが解析し、テキストデータに変換する技術。<strong>【活用例】</strong>スマートスピーカー（Amazon Echo）、Zoomの自動文字起こし機能、コールセンターでの通話内容のテキスト化。' },
            { term: '推薦システム (レコメンデーション)', category: '応用分野', description: 'ユーザーの履歴などから好みに合いそうな項目を推薦するシステム。<strong>【技術詳細】</strong>ユーザーの行動履歴から推薦する「協調フィルタリング」、アイテムの類似性から推薦する「コンテンツベースフィルタリング」などがある。' },
            { term: 'エッジAI', category: '応用分野', description: 'クラウドではなく、端末（エッジ）側でAIの推論処理を行う技術。<strong>【技術詳細】</strong>モデルの軽量化技術（量子化、プルーニングなど）が重要となる。通信遅延の低減やプライバシー保護の観点で注目されている。' },
            { term: 'DX (デジタルトランスフォーメーション)', category: '応用分野', description: 'AIやIoTなどのデジタル技術を活用して、ビジネスモデルや業務を変革すること。<strong>【具体例】</strong>熟練工の技術をAIに学習させて品質管理を自動化する、顧客データを分析して一人ひとりに最適なサービスを提供するなど。' },
            { term: 'AGI (汎用人工知能)', category: '応用分野', description: '特定のタスクに特化した現在のAI（特化型AI）とは異なり、人間のように様々なタスクを柔軟にこなし、自ら学習できるAIのこと。まだ実現には至っていない。'},
            { term: 'コグニティブ・コンピューティング', category: '応用分野', description: '人間のように経験から学習し、文脈を理解し、対話できるコンピュータシステム。IBMの「Watson」が代表例。'},
            { term: 'RPA (Robotic Process Automation)', category: '応用分野', description: 'ソフトウェアロボットを用いて、PC上の定型的な事務作業を自動化する技術。AIと組み合わせることで、より高度で非定型な業務の自動化も可能になる。'}
        ];

        const detailedExplanations = {};

        // 全用語の詳細解説を生成
        termsData.forEach(term => {
            let explanation = `<h4>${term.term} 詳細解説</h4>`;
            explanation += `<p>${term.description.replace(/<strong>.*?<\/strong>/g, '')}</p>`; // 基本説明を追加
            
            // 各用語に特化した解説を追加
            switch (term.term) {
                // --- 歴史・人物 ---
                case 'アラン・チューリング': explanation += `<h4>G検定でのポイント</h4><p>「AIの父」として必ず問われる人物です。彼が提唱した「チューリングテスト」は、機械に知能があるかを判定する思考実験で、AIの哲学的な議論の基礎となりました。また、計算可能なものはすべて「チューリングマシン」という仮想機械で実行できるという概念も提唱し、これが現代のコンピュータの理論的基礎となっています。</p>`; break;
                case 'ジョン・マッカーシー': explanation += `<h4>G検定でのポイント</h4><p>1956年に開催された「ダートマス会議」の名付け親であり、この会議で初めて「人工知能(AI)」という学術分野を提唱した中心人物です。そのため「AIの父」とも呼ばれます。また、AI研究で広く使われたプログラミング言語「LISP」を開発したことでも知られています。</p>`; break;
                case 'マービン・ミンスキー': explanation += `<h4>G検定でのポイント</h4><p>ダートマス会議に参加したAI研究の創始者の一人です。シーモア・パパートと共に著書「パーセプトロン」で、単純パーセプトロンの限界（XORのような線形分離不可能な問題が解けないこと）を数学的に証明し、第一次AIブームの終焉を招いたとされています。一方で、知識を構造的に表現する「フレーム理論」を提唱し、その後の知識ベースAIの研究に大きな影響を与えました。</p>`; break;
                case 'アーサー・サミュエル': explanation += `<h4>G検定でのポイント</h4><p>IBMの研究者で、機械学習分野のパイオニアです。1959年に発表したチェッカーのプログラムは、自己対戦を通じて学習し、やがて人間のトッププレイヤーを打ち負かすレベルに達しました。彼自身が「明示的にプログラムすることなく学習する能力をコンピュータに与える研究分野」と定義したことが、「機械学習」という言葉の起源とされています。</p>`; break;
                case 'フランク・ローゼンブラット': explanation += `<h4>G検定でのポイント</h4><p>アメリカの心理学者・計算機科学者で、1957年に「パーセプトロン」を発表しました。これは人間の脳の神経細胞の働きを模倣したモデルで、パターン認識の能力を持っていました。現代のニューラルネットワークの直接の祖先であり、AI研究の初期における重要なマイルストーンです。</p>`; break;
                case 'ジェフリー・ヒントン': explanation += `<h4>G検定でのポイント</h4><p>2012年の画像認識コンテストILSVRCで、自身らが開発したCNNモデル「AlexNet」で圧勝し、第三次AIブームの火付け役となりました。「誤差逆伝播法」を広く普及させ、ディープラーニングの学習を可能にした功績も非常に大きいです。ヤン・ルカン、ヨシュア・ベンジオと共に2018年のチューリング賞を受賞しました。</p>`; break;
                case 'ヤン・ルカン': explanation += `<h4>G検定でのポイント</h4><p>手書き文字認識で高い性能を発揮したCNNモデル「LeNet」の開発者として有名です。畳み込み層とプーリング層を組み合わせるというCNNの基本構造を確立しました。現在はMeta社(旧Facebook)のチーフAIサイエンティストを務めています。</p>`; break;
                case 'ヨシュア・ベンジオ': explanation += `<h4>G検定でのポイント</h4><p>特に自然言語処理分野における、単語のベクトル表現（分散表現）や、RNN、Attention機構などの研究で大きな功績があります。AIの倫理的な側面にも積極的に発言していることでも知られています。</p>`; break;
                case 'レイ・カーツワイル': explanation += `<h4>G検定でのポイント</h4><p>「シンギュラリティ」という言葉を一般に広めた人物として重要です。「収穫加速の法則」を提唱し、技術の進化は直線的ではなく指数関数的に加速すると主張しました。現在はGoogleでAI開発の責任者を務めています。</p>`; break;
                case 'ジョン・サール': explanation += `<h4>G検定でのポイント</h4><p>「中国語の部屋」は、「記号をルール通りに処理すること」と「真に意味を理解すること」は違うと主張する思考実験です。AIの能力を議論する上で頻出のトピックです。「強いAI（意識を持つAI）」と「弱いAI（便利な道具としてのAI）」の区別も重要です。</p>`; break;
                case 'ロドニー・ブルックス': explanation += `<h4>G検定でのポイント</h4><p>マサチューセッツ工科大学の教授で、ロボット工学の権威です。従来の、世界を記号でモデル化してから行動計画を立てるAI（記号接地AI）を批判しました。そして、シンプルな反射的な行動の組み合わせ（包摂アーキテクチャ）によって、複雑なタスクをこなす自律ロボットが実現できると主張しました。この考えは、お掃除ロボット「ルンバ」の開発に繋がりました。</p>`; break;
                case 'ダートマス会議': explanation += `<h4>G検定でのポイント</h4><p>1956年に開催されたこの会議には、ジョン・マッカーシー、マービン・ミンスキー、クロード・シャノンなど、後のAI研究を牽引する多くの科学者が参加しました。「人工知能」という学問分野がここから始まった、という歴史的な意義を理解しておくことが重要です。</p>`; break;
                case 'AIの冬の時代': explanation += `<h4>G検定でのポイント</h4><p>ブームと停滞期を繰り返してきたのがAIの歴史です。第一次ブームは単純パーセプトロンの限界が露呈したこと、第二次ブームはエキスパートシステムの限界が明らかになったことなどが原因で終焉を迎えました。このような歴史的背景を知ることで、現在の第三次AIブームを相対的に理解できます。</p>`; break;
                case 'エキスパートシステム': explanation += `<h4>G検定でのポイント</h4><p>専門家の知識を「if-thenルール」のような形式でコンピュータに記述し、特定の分野の問題解決を行うシステムです。第二次AIブームを牽引しましたが、専門家の知識を網羅的にルール化することの困難さ（知識獲得のボトルネック）や、例外的な状況に対応できないという問題に直面し、ブームは下火になりました。</p>`; break;
                
                // --- 機械学習 ---
                case '教師あり学習': explanation += `<h4>G検定でのポイント</h4><ul><li><strong>回帰:</strong> 目的変数が連続値（例：株価、気温、家の価格など）。</li><li><strong>分類:</strong> 目的変数がカテゴリ（例：スパムか否か、犬か猫か、病気の種類など）。</li></ul><p>この2つの違いと具体例をしっかり押さえることが重要です。</p>`; break;
                case '教師なし学習': explanation += `<h4>G検定でのポイント</h4><ul><li><strong>クラスタリング:</strong> データを似たもの同士のグループに分ける手法（例：顧客セグメンテーション）。k-means法が代表的。</li><li><strong>次元削減:</strong> データの次元（特徴量の数）を減らす手法（例：アンケート結果の要約）。主成分分析(PCA)が代表的。</li></ul><p>教師あり学習との根本的な違い（正解データの有無）を理解しましょう。</p>`; break;
                case '強化学習': explanation += `<h4>G検定でのポイント</h4><p>教師あり学習や教師なし学習との違いを明確に理解することが重要です。強化学習は「明確な正解データ」がない代わりに、「行動の結果としての報酬」を頼りに学習を進めます。囲碁AIのAlphaGoが代表例としてよく挙げられます。</p>`; break;
                case '半教師あり学習': explanation += `<h4>G検定でのポイント</h4><p>教師あり・教師なし・強化学習との違いを理解することが重要です。ラベル付けコストが高い現実世界の課題（例：大量の画像の中から特定の種類の画像だけを分類したいが、全てにラベルを付けるのは大変）を解決するアプローチとして注目されています。</p>`; break;
                case '自己教師あり学習': explanation += `<h4>G検定でのポイント</h4><p>TransformerベースのBERTやGPTといった近年の大規模言語モデルの成功の根幹を支える技術です。大量のラベルなしデータ（Web上のテキストなど）から、AIが自ら問題を作って解くことで、汎用的な言語能力を獲得できるという点が画期的です。</p>`; break;
                case '回帰 (Regression)': explanation += `<h4>G検定でのポイント</h4><p>「分類」との違いを明確に理解することが重要です。連続的な数値を予測するタスクであり、代表的なアルゴリズムとして線形回帰、決定木、ランダムフォレストなどがあります。</p>`; break;
                case '分類 (Classification)': explanation += `<h4>G検定でのポイント</h4><p>「回帰」との違いを明確に理解することが重要です。カテゴリを予測するタスクであり、2値分類（例：迷惑メールか否か）と多クラス分類（例：犬、猫、鳥のどれか）があります。</p>`; break;
                case 'ロジスティック回帰': explanation += `<h4>G検定でのポイント</h4><p>名前は「回帰」とついていますが、「分類」のための手法である点に注意が必要です。単純で解釈しやすいため、多くの分類問題のベースラインとして利用されます。</p>`; break;
                case 'k-NN法 (k近傍法)': explanation += `<h4>G検定でのポイント</h4><p>アルゴリズムが非常に単純で理解しやすいのが特徴です。一方で、データ量が増えると予測に時間がかかるという欠点があります。「怠惰学習」または「事例ベース学習」の代表例として覚えておきましょう。</p>`; break;
                case '過学習 (Overfitting)': explanation += `<h4>G検定でのポイント</h4><p>過学習はモデルの「汎化性能」が低い状態を指します。これを防ぐための技術（正則化、ドロップアウト、データ拡張など）とセットで問われることが多いです。「バイアスとバリアンスのトレードオフ」の観点から、高バリアンスな状態であることも理解しておきましょう。</p>`; break;
                case '正則化 (Regularization)': explanation += `<h4>G検定でのポイント</h4><p>過学習を防ぐための代表的な手法です。L1正則化とL2正則化の違い（L1は不要な特徴量の重みを0にするため特徴量選択の効果がある）を理解しておくことが重要です。</p>`; break;
                case 'サポートベクターマシン (SVM)': explanation += `<h4>G検定でのポイント</h4><p>「マージン最大化」と「カーネルトリック」が最重要キーワードです。かつては非常に高い性能を誇る分類器として、ディープラーニング以前の時代に広く使われていました。</p>`; break;
                case 'アンサンブル学習': explanation += `<h4>G検定でのポイント</h4><p>単一のモデルよりも高い精度と安定性を得られるため、実際のデータ分析コンペティション（Kaggleなど）で頻繁に利用されます。「バギング」「ブースティング」という代表的な2つのアプローチの違いを理解することが重要です。</p>`; break;
                case 'ハイパーパラメータ': explanation += `<h4>G検定でのポイント</h4><p>モデル自身が学習して決める「パラメータ（重みやバイアス）」とは区別される、人間が事前に設定するパラメータであるという点を理解しましょう。この調整作業を「ハイパーパラメータチューニング」と呼びます。</p>`; break;

                // --- ディープラーニング ---
                case 'ニューラルネットワーク': explanation += `<h4>G検定でのポイント</h4><p>入力層、中間層（隠れ層）、出力層の3つの層から構成されるのが基本です。中間層が多層になったものがディープニューラルネットワーク（DNN）であり、ディープラーニングの中核をなします。</p>`; break;
                case '活性化関数': explanation += `<h4>G検定でのポイント</h4><p>活性化関数がなければ、ニューラルネットワークはただの線形変換の積み重ねとなり、複雑なパターンを学習できません。非線形な関数を導入することが、モデルの表現力を高める上で不可欠です。ReLUが現在最も一般的に使われる理由（勾配消失問題の緩和）も押さえておきましょう。</p>`; break;
                case '誤差逆伝播法': explanation += `<h4>G検定でのポイント</h4><p>ディープラーニングモデルの学習における最も基本的なアルゴリズムです。計算された誤差を微分によって各層のパラメータにフィードバックし、勾配降下法によってパラメータを更新していく、という流れを理解しましょう。</p>`; break;
                case '最適化アルゴリズム (Optimizer)': explanation += `<h4>G検定でのポイント</h4><p>様々な種類がありますが、現在は「Adam」がデファクトスタンダードとして広く利用されています。それぞれのアルゴリズムが、勾配降下法をどのように改良しているのか（例：Momentumは慣性、Adamは適応的な学習率）を大まかに把握しておくと良いでしょう。</p>`; break;
                case '学習率 (Learning Rate)': explanation += `<h4>G検定でのポイント</h4><p>モデルの学習がうまくいくかを左右する、最も重要なハイパーパラメータの一つです。学習率を最初大きく設定し、学習が進むにつれて徐々に小さくしていく「学習率スケジューリング」というテクニックもよく使われます。</p>`; break;
                case 'ドロップアウト (Dropout)': explanation += `<h4>G検定でのポイント</h4><p>非常に強力な正則化手法であり、過学習対策として頻繁に利用されます。学習時のみ適用され、推論（予測）時にはすべてのニューロンを使用するという点も重要です。</p>`; break;
                case '勾配消失/爆発問題': explanation += `<h4>G検定でのポイント</h4><p>特に深いネットワーク（層が多いモデル）で顕著になる問題です。この問題を解決するために、活性化関数の工夫（ReLU）、バッチ正規化、残差接続（ResNet）、ゲート付きRNN（LSTM, GRU）などの様々な技術が開発されました。</p>`; break;
                case 'バッチ正規化': explanation += `<h4>G検定でのポイント</h4><p>学習の高速化・安定化に大きく貢献する重要な技術です。CNNの畳み込み層や全結合層の後に挿入されるのが一般的です。</p>`; break;
                case 'CNN (畳み込みニューラルネットワーク)': explanation += `<h4>G検定でのポイント</h4><p>「畳み込み層」と「プーリング層」がセットで使われることが特徴です。画像データに対して圧倒的な性能を発揮し、第三次AIブームの火付け役となりました。LeNet, AlexNet, VGG, ResNetといった代表的なモデル名と、その進化の歴史も重要です。</p>`; break;
                case 'RNN (再帰型ニューラルネットワーク)': explanation += `<h4>G検定でのポイント</h4><p>時系列データや自然言語のように、データの順序が意味を持つ場合に利用されます。ただし、長期的な依存関係の学習が苦手（長期依存性問題）という欠点があり、それを克服するためにLSTMやGRUが開発されました。</p>`; break;
                case 'LSTM (Long Short-Term Memory)': explanation += `<h4>G検定でのポイント</h4><p>RNNの長期依存性問題を解決したモデルとして非常に重要です。「ゲート」という特殊な構造によって、情報の取捨選択を可能にした点が画期的です。Seq2Seqモデルなどで広く利用されてきました。</p>`; break;
                case 'GRU (Gated Recurrent Unit)': explanation += `<h4>G検定でのポイント</h4><p>LSTMをよりシンプルな構造にしたモデルです。性能はLSTMに匹敵することが多く、計算コストが低いため、選択肢の一つとして知られています。</p>`; break;
                case 'Seq2Seq': explanation += `<h4>G検定でのポイント</h4><p>エンコーダ・デコーダモデルの代表例です。入力文を一つのベクトルに押し込める部分が情報のボトルネックになりやすいという課題があり、それを解決するために「Attention機構」が考案されました。</p>`; break;
                case 'Transformer': explanation += `<h4>G検定でのポイント</h4><p>Transformerが、その後のBERTやGPTといった大規模言語モデル(LLM)の基盤技術となったという流れは非常に重要です。自然言語処理の歴史におけるブレークスルーとして認識しておきましょう。</p>`; break;
                case 'Attention (アテンション) 機構': explanation += `<h4>G検定でのポイント</h4><p>元々はSeq2Seqモデルの性能向上のために考案されましたが、Transformerではモデルの根幹をなす要素となりました。文章中のどの単語に「注目」すべきか、その重みを動的に計算するというアイデアが重要です。</p>`; break;
                case '転移学習 (Transfer Learning)': explanation += `<h4>G検定でのポイント</h4><p>現代のディープラーニング開発では必須のテクニックです。巨大なデータセットで事前学習されたモデル（学習済みモデル）を利用することで、少ないデータでも高い精度のモデルを効率的に開発できます。</p>`; break;
                case 'GAN (敵対的生成ネットワーク)': explanation += `<h4>G検定でのポイント</h4><p>「生成モデル」の一種であり、そのユニークな学習方法（敵対的学習）が特徴です。高品質な画像生成能力から、ディープフェイクなどの倫理的な問題と関連付けて問われることもあります。</p>`; break;
                case 'オートエンコーダ': explanation += `<h4>G検定でのポイント</h4><p>教師なし学習の手法であり、次元削減や異常検知に応用されます。入力データを一度低次元の潜在変数に圧縮（エンコード）し、それを元に復元（デコード）するという構造を理解しておきましょう。</p>`; break;
                case 'ResNet (Residual Network)': explanation += `<h4>G検定でのポイント</h4><p>「スキップ接続（残差接続）」というキーワードが最重要です。この仕組みにより、それまで困難だった100層を超えるような非常に深いネットワークの学習が可能になり、画像認識の精度を大きく向上させました。</p>`; break;
                case 'BERT': explanation += `<h4>G検定でのポイント</h4><p>Transformerのエンコーダ部分を利用したモデルです。「双方向」から文脈を理解する点が画期的であり、それ以前のモデル（GPTなど）を一気に時代遅れにしました。様々な自然言語処理タスクの性能を大幅に塗り替えたモデルとして重要です。</p>`; break;
                case 'GPT (Generative Pre-trained Transformer)': explanation += `<h4>G検定でのポイント</h4><p>Transformerのデコーダ部分を利用したモデルです。BERTとは対照的に、次に来る単語を予測することで、非常に流暢な文章を生成することを得意としています。ChatGPTの成功により、その名が広く知られるようになりました。</p>`; break;
                case '物体検出 (Object Detection)': explanation += `<h4>G検定でのポイント</h4><p>単なる「分類」だけでなく、物体の「位置（バウンディングボックス）」も同時に予測するタスクです。自動運転における歩行者や車両の検出など、実世界での応用範囲が非常に広いです。</p>`; break;
                case 'セマンティックセグメンテーション': explanation += `<h4>G検定でのポイント</h4><p>「ピクセル単位の分類」であるという点が重要です。物体検出よりもさらに詳細な領域の特定が可能で、医療画像の解析や自動運転の走行可能領域の認識などに利用されます。</p>`; break;
                case 'モデル圧縮': explanation += `<h4>G検定でのポイント</h4><p>ディープラーニングモデルをスマートフォンなどのエッジデバイスで動作させる（エッジAI）ために不可欠な技術群です。代表的な手法である「量子化」「枝刈り」「知識蒸留」の概要は押さえておきましょう。</p>`; break;
                
                // --- データサイエンス・統計 ---
                case 'EDA (探索的データ分析)': explanation += `<h4>G検定でのポイント</h4><p>機械学習モデルを構築する前の、非常に重要な準備段階です。データへの理解を深めることで、適切な前処理やモデル選択の方針を立てることができます。</p>`; break;
                case '特徴量エンジニアリング': explanation += `<h4>G検定でのポイント</h4><p>モデルの性能を最も大きく左右すると言われることもある重要な工程です。「Garbage In, Garbage Out（ゴミを入れればゴミしか出てこない）」という言葉が示す通り、質の悪いデータをいくら高度なモデルに入れても良い結果は得られません。</p>`; break;
                case '欠損値処理': explanation += `<h4>G検定でのポイント</h4><p>データ分析の前処理として必須の作業です。どのような手法で欠損値を処理したかが、後のモデルの性能に影響を与える可能性があります。</p>`; break;
                case 'データ拡張 (Data Augmentation)': explanation += `<h4>G検定でのポイント</h4><p>特に画像認識の分野で、過学習を防ぎモデルの汎化性能を高めるための常套手段となっています。少ないデータからでも、より頑健なモデルを作成するのに役立ちます。</p>`; break;
                case '標準化と正規化': explanation += `<h4>G検定でのポイント</h4><p>特徴量ごとに数値のスケールが大きく異なると、モデルの学習がうまくいかないことがあります。特に、距離を計算するアルゴリズム（k-NN、SVMなど）や、勾配降下法を用いる多くのモデルで効果的です。</p>`; break;
                case '混合行列 (Confusion Matrix)': explanation += `<h4>G検定でのポイント</h4><p>この表の4つの要素から、<strong>適合率(Precision)</strong>、<strong>再現率(Recall)</strong>、<strong>F値</strong>といった重要な評価指標が計算されます。単に正解率(Accuracy)を見るだけでは、特に不均衡データの場合にモデルの性能を正しく評価できないため、これらの指標がなぜ重要なのかを理解しておくことが大切です。</p>`; break;
                case '適合率 (Precision) と 再現率 (Recall)': explanation += `<h4>G検定でのポイント</h4><p>どちらを重視すべきかは、タスクの目的によって異なります。例えば、迷惑メール判定では「通常メールを迷惑メールと誤判定しないこと」が重要なので適合率が重視されます。一方、病気の診断では「病気を見逃さないこと」が最優先なので再現率が重視されます。</p>`; break;
                case 'F値 (F-measure)': explanation += `<h4>G検定でのポイント</h4><p>適合率と再現率がトレードオフの関係にあるため、両方をバランスよく評価したい場合に用いられる総合的な指標です。</p>`; break;
                case 'ROC曲線・AUC': explanation += `<h4>G検定でのポイント</h4><p>AUCは、モデルがどれだけ陽性クラスと陰性クラスをうまく分離できているかを示す指標と解釈できます。0.5はランダムな予測と同じで、1.0が完璧なモデルを意味します。</p>`; break;
                case 'バイアスとバリアンス': explanation += `<h4>G検定でのポイント</h4><p>両者のトレードオフの関係性が重要です。モデルが複雑になるほどバイアスは低下しますが、バリアンスは増加（過学習のリスク）します。逆にモデルが単純すぎるとバリアンスは低下しますが、バイアスは増加（学習不足）します。このバランスを取ることが良いモデル作成の鍵です。</p>`; break;
                case 'p値 (p-value)': explanation += `<h4>G検定でのポイント</h4><p>p値が小さいことは統計的に「偶然とは考えにくい」ことを示しますが、それが「効果が大きい」ことや「因果関係がある」ことを直接意味するわけではない点に注意が必要です。</p>`; break;
                case '不均衡データ (Imbalanced Data)': explanation += `<h4>G検定でのポイント</h4><p>クレジットカードの不正利用検知や、工場の不良品検知など、現実世界の多くの問題は不均衡データです。そのため、適切な対処法（サンプリング手法の適用や、評価指標としてAccuracyではなくF値やAUCを用いるなど）を知っていることが重要です。</p>`; break;
                
                // --- ハードウェア・インフラ ---
                case 'GPU (Graphics Processing Unit)': explanation += `<h4>G検定でのポイント</h4><p>「ディープラーニングの発展はGPUの進化なくしてはあり得なかった」という点は非常に重要です。特にNVIDIA社が開発した<code>CUDA</code>という並列コンピューティングプラットフォームにより、GPUを汎用的な計算に利用する<code>GPGPU</code>という技術が普及し、AI研究が加速しました。この背景を理解しておきましょう。</p>`; break;
                case 'TPU (Tensor Processing Unit)': explanation += `<h4>G検定でのポイント</h4><p>Googleが自社のサービス（翻訳、検索など）とクラウドサービスのために開発した専用ハードウェアです。特に推論処理において高い電力効率を誇ります。</p>`; break;
                case 'FPGA (Field-Programmable Gate Array)': explanation += `<h4>G検定でのポイント</h4><p>GPUやTPUほど汎用的ではありませんが、特定のタスクに特化した回路を設計することで、非常に低遅延な処理が可能です。そのため、リアルタイム性が求められるエッジデバイスでの推論などに利用されます。</p>`; break;
                case 'クラウドコンピューティング': explanation += `<h4>G検定でのポイント</h4><p>自前で高価な計算機サーバーを保有することなく、必要な時に必要なだけ計算リソースを利用できるため、AI開発のハードルを大きく下げました。代表的なサービス（AWS, GCP, Azure）と、それぞれが提供するAI関連サービス（Amazon SageMaker, Google Vertex AI, Azure Machine Learningなど）の名前は知っておくと良いでしょう。</p>`; break;
                case 'コンテナ技術': explanation += `<h4>G検定でのポイント</h4><p>AIモデルを開発した環境と、実際に運用する環境の違いによる問題を解消できるため、MLOpsにおいて重要な役割を果たします。Dockerが事実上の標準となっています。</p>`; break;
                case 'Kubernetes': explanation += `<h4>G検定でのポイント</h4><p>多数のコンテナを協調させて、大規模なサービスを安定運用するための管理ツールです。Googleが開発した技術がオープンソース化されたものです。</p>`; break;
                case 'MLOps': explanation += `<h4>G検定でのポイント</h4><p>AIモデルは一度作って終わりではなく、継続的に性能を監視し、新しいデータで再学習させて改善していく必要があります。MLOpsは、そのための仕組みや文化全体を指す言葉として重要です。</p>`; break;
                
                // --- 法律・倫理 ---
                case '個人情報保護法': explanation += `<h4>G検定でのポイント</h4><p>氏名や住所だけでなく、他の情報と組み合わせることで個人を特定できる情報（例：購買履歴と会員ID）も個人情報に含まれる場合があります。また、本人の同意なく個人情報を第三者に提供することは原則禁止されています。</p>`; break;
                case '著作権法': explanation += `<h4>G検定でのポイント</h4><p>AIの学習データとしてWeb上のコンテンツを利用する場合や、画像生成AIの出力など、AIと著作権の問題はG検定でも頻出のトピックです。思想や感情の創作的な表現が保護対象であり、単なるデータは対象外であるという基本を理解しておきましょう。</p>`; break;
                case 'GDPR (一般データ保護規則)': explanation += `<h4>G検定でのポイント</h4><p>EU域内の個人データを扱うすべての事業者が対象となるため、日本の企業も無関係ではありません。「忘れられる権利」や「データポータビリティの権利」など、個人の権利を強く保護している点が特徴です。</p>`; break;
                case 'AI開発原則': explanation += `<h4>G検定でのポイント</h4><p>これらは法的な拘束力を持つものではありませんが（ソフトロー）、AIを開発・利用する上で遵守すべき倫理的な指針として、国内外の多くの組織が同様の原則を公表しています。</p>`; break;
                case '説明可能なAI (XAI)': explanation += `<h4>なぜ重要か？</h4><p>AIの判断が「ブラックボックス」のままだと、以下のような問題が生じます。</p><ul><li><strong>信頼性の欠如:</strong> なぜその結論に至ったのか分からないと、ユーザーはAIの判断を信頼できません。特に医療診断や融資審査など、重要な意思決定で問題となります。</li><li><strong>公平性の担保:</strong> AIが意図せず不公平なバイアス（偏見）に基づいて判断していたとしても、それを発見・修正することが困難です。</li><li><strong>安全性の確保:</strong> 自動運転車がなぜ特定の操作をしたのか分からなければ、事故原因の究明や再発防止ができません。</li></ul><h4>G検定でのポイント</h4><p>GDPR（EU一般データ保護規則）では「説明を受ける権利」が明記されるなど、XAIは法規制や社会的な要請としても重要度が増しています。具体的な手法として、モデル全体の判断傾向を説明する<code>LIME</code>や<code>SHAP</code>、CNNが画像のどこに注目したかを可視化する<code>Grad-CAM</code>などの名称も覚えておくと良いでしょう。</p>`; break;
                case 'アルゴリズムの公平性 / バイアス': explanation += `<h4>G検定でのポイント</h4><p>学習データに含まれる社会的な偏見をAIが増幅・再生産してしまうリスクが問題視されています。採用、融資、司法など、社会的に重要な分野でのAI利用において特に重要な課題です。</p>`; break;
                case 'フレーム問題': explanation += `<h4>G検定でのポイント</h4><p>記号的AIが直面した根源的な困難さを示す問題です。「人間は常識によって無関係なことを自然に無視しているが、コンピュータにそれをどう教えるか」という問題とも言えます。</p>`; break;
                case 'シンボルグラウンディング問題': explanation += `<h4>G検定でのポイント</h4><p>「中国語の部屋」の思考実験とも関連する哲学的な問題です。例えば、AIが「犬」という記号（単語）を扱えても、それが実世界の「犬」という存在と結びついていなければ、真に理解しているとは言えない、という議論です。</p>`; break;
                case 'ディープフェイク': explanation += `<h4>G検定でのポイント</h4><p>フェイクニュースの拡散や、個人の名誉毀損など、社会的な混乱を招くリスクが懸念されています。GAN（敵対的生成ネットワーク）の技術が悪用された例として頻出します。</p>`; break;
                case 'トロリー問題': explanation += `<h4>G検定でのポイント</h4><p>AI、特に自動運転のような自律システムに、倫理的な判断をどう実装するかという問題の難しさを示す例として挙げられます。どの選択肢が「正解」かは人間でも結論が出ないため、AIにそれをプログラムすることの困難さを示唆しています。</p>`; break;
                
                // --- 応用分野 ---
                case '自然言語処理 (NLP)': explanation += `<h4>G検定でのポイント</h4><p>形態素解析、構文解析、意味解析といった伝統的な手法から、Transformerベースの大規模言語モデルまで、幅広い技術が含まれます。近年のAIの進化を最も象徴する分野の一つです。</p>`; break;
                case '画像認識': explanation += `<h4>G検定でのポイント</h4><p>CNNの登場によって精度が飛躍的に向上しました。「分類」「物体検出」「セグメンテーション」など、タスクによって目的が異なることを理解しましょう。ILSVRCという画像認識コンペが技術発展の大きなマイルストーンとなりました。</p>`; break;
                case '音声認識': explanation += `<h4>G検定でのポイント</h4><p>音響モデル（音声を音素に変換）と、言語モデル（音素の並びを単語や文章に変換）を組み合わせて実現されます。ディープラーニングの導入により、こちらも精度が大幅に向上しました。</p>`; break;
                case '推薦システム (レコメンデーション)': explanation += `<h4>G検定でのポイント</h4><p>ECサイトや動画配信サービスなど、多くのWebサービスで顧客体験の向上と売上増加のために利用されています。「協調フィルタリング」は「あなたと似た興味を持つ他のユーザー」の行動に基づいて推薦する手法として重要です。</p>`; break;
                case 'エッジAI': explanation += `<h4>G検定でのポイント</h4><p>すべてのデータをクラウドに送る必要がないため、①通信遅延が少ない（リアルタイム性が高い）、②オフラインでも動作する、③プライバシー保護に繋がる、といったメリットがあります。スマートフォンや自動車、監視カメラなどがエッジデバイスの例です。</p>`; break;
                case 'DX (デジタルトランスフォーメーション)': explanation += `<h4>G検定でのポイント</h4><p>単なるデジタル化（デジタイゼーション）や業務効率化（デジタライゼーション）に留まらず、AIなどのデジタル技術を前提として、ビジネスモデルそのものを変革し、新たな価値を創出することがDXの本質です。</p>`; break;
                case 'AGI (汎用人工知能)': explanation += `<h4>G検定でのポイント</h4><p>現在主流のAIは、特定のタスクに特化した「特化型AI（Narrow AI）」です。AGIは、まだSFの世界の話ですが、AI研究の究極的な目標の一つとして議論されます。</p>`; break;
                case 'コグニティブ・コンピューティング': explanation += `<h4>G検定でのポイント</h4><p>IBMが提唱している概念で、同社のAI「Watson」がその代表例です。データから自律的に学習し、人間と自然な対話を通じて意思決定を支援することを目的としています。</p>`; break;
                case 'RPA (Robotic Process Automation)': explanation += `<h4>G検定でのポイント</h4><p>主にルールベースで動作する定型業務の自動化ツールです。AI、特にOCR（光学的文字認識）や自然言語処理と組み合わせることで、請求書の読み取りなど、より高度な業務の自動化が可能になる「インテリジェント・オートメーション」という概念も重要です。</p>`; break;

            }
            detailedExplanations[term.term] = explanation;
        });

        const searchInput = document.getElementById('searchInput');
        const categoryFilters = document.getElementById('categoryFilters');
        const termList = document.getElementById('termList');
        const noResults = document.getElementById('noResults');
        const explanationModal = document.getElementById('explanationModal');
        const modalTitle = document.getElementById('modalTitle');
        const closeModalBtn = document.getElementById('closeModalBtn');
        const detailedExplanationEl = document.getElementById('detailedExplanation');

        let currentCategory = 'all';

        // 用語カードをレンダリングする関数
        const renderTerms = (filteredTerms) => {
            termList.innerHTML = '';
            if (filteredTerms.length === 0) {
                noResults.classList.remove('hidden');
            } else {
                noResults.classList.add('hidden');
            }

            // 用語をあいうえお順でソート
            filteredTerms.sort((a, b) => a.term.localeCompare(b.term, 'ja'));

            filteredTerms.forEach(term => {
                const card = document.createElement('div');
                card.className = 'bg-gray-800 rounded-lg shadow-lg p-6 pb-12 transition-all duration-300 hover:shadow-cyan-500/20 hover:-translate-y-1 flex flex-col relative';
                
                const categoryColor = {
                    '歴史・人物': 'bg-rose-500/20 text-rose-300',
                    '機械学習': 'bg-amber-500/20 text-amber-300',
                    'ディープラーニング': 'bg-cyan-500/20 text-cyan-300',
                    'データサイエンス・統計': 'bg-lime-500/20 text-lime-300',
                    'ハードウェア・インフラ': 'bg-teal-500/20 text-teal-300',
                    '法律・倫理': 'bg-violet-500/20 text-violet-300',
                    '応用分野': 'bg-emerald-500/20 text-emerald-300',
                };

                card.innerHTML = `
                    <div class="flex justify-between items-start mb-2">
                        <h3 class="text-xl font-bold text-gray-100">${term.term}</h3>
                        <span class="text-xs font-semibold px-2.5 py-0.5 rounded-full flex-shrink-0 ml-2 ${categoryColor[term.category] || 'bg-gray-700'}">${term.category}</span>
                    </div>
                    <p class="text-gray-400 font-light leading-relaxed flex-grow term-description">${term.description}</p>
                    <button class="show-explanation-btn absolute bottom-3 right-3 p-2 rounded-full bg-cyan-600/80 hover:bg-cyan-500 transition-all text-xl" title="詳細解説を見る" data-term="${term.term}">
                        ✨
                    </button>
                `;
                termList.appendChild(card);
            });
        };

        // フィルタリングとレンダリングを実行する関数
        const filterAndRender = () => {
            const searchTerm = searchInput.value.toLowerCase();
            
            let filteredTerms = termsData.filter(term => {
                const inCategory = currentCategory === 'all' || term.category === currentCategory;
                const inSearch = term.term.toLowerCase().includes(searchTerm) || term.description.toLowerCase().includes(searchTerm);
                return inCategory && inSearch;
            });
            
            renderTerms(filteredTerms);
        };
        
        // モーダルにサンプル回答を表示する関数
        const showDetailedExplanation = (term) => {
            const explanation = detailedExplanations[term];
            detailedExplanationEl.innerHTML = explanation;
        };

        // モーダルを開く関数
        const openModal = (term) => {
            modalTitle.textContent = `「${term}」の詳細解説`;
            showDetailedExplanation(term);
            explanationModal.classList.remove('hidden');
            explanationModal.classList.add('flex');
            setTimeout(() => {
                explanationModal.classList.add('opacity-100');
                explanationModal.querySelector('.transform').classList.add('scale-100');
            }, 10);
        };

        // モーダルを閉じる関数
        const closeModal = () => {
            explanationModal.classList.remove('opacity-100');
            explanationModal.querySelector('.transform').classList.remove('scale-100');
            setTimeout(() => {
                explanationModal.classList.add('hidden');
                explanationModal.classList.remove('flex');
            }, 300);
        };


        // イベントリスナー
        searchInput.addEventListener('input', filterAndRender);

        categoryFilters.addEventListener('click', (e) => {
            if (e.target.tagName === 'BUTTON') {
                document.querySelector('.filter-btn.active').classList.remove('active');
                e.target.classList.add('active');
                currentCategory = e.target.dataset.category;
                filterAndRender();
            }
        });

        termList.addEventListener('click', (e) => {
            const btn = e.target.closest('.show-explanation-btn');
            if (btn) {
                const term = btn.dataset.term;
                openModal(term);
            }
        });
        
        closeModalBtn.addEventListener('click', closeModal);
        explanationModal.addEventListener('click', (e) => {
            if (e.target === explanationModal) {
                closeModal();
            }
        });
        
        // カテゴリボタンのスタイリング
        const buttons = categoryFilters.querySelectorAll('.filter-btn');
        buttons.forEach(button => {
            button.classList.add('px-4', 'py-2', 'text-sm', 'font-medium', 'text-gray-300', 'bg-gray-800', 'rounded-full', 'hover:bg-gray-700', 'transition-colors', 'whitespace-nowrap');
            if (button.classList.contains('active')) {
                button.classList.add('!bg-cyan-600', '!text-white');
            }
        });

        // 初期表示
        filterAndRender();

        // アクティブなボタンのスタイルを上書きするためのCSSを追加
        const style = document.createElement('style');
        style.textContent = `
            .filter-btn.active {
                background-color: #0891b2 !important; /* Tailwindのcyan-600 */
                color: white !important;
                box-shadow: 0 0 10px 2px rgba(14, 165, 233, 0.4); /* Tailwindのcyan-500/40 */
            }
        `;
        document.head.appendChild(style);

    </script>
</body>
</html>
