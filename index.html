<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>G検定 最強チートシート (全解説表示版)</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;700&family=Noto+Sans+JP:wght@400;500;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', 'Noto Sans JP', sans-serif;
            -webkit-font-smoothing: antialiased;
            -moz-osx-font-smoothing: grayscale;
        }
        /* スクロールバーのスタイル */
        ::-webkit-scrollbar {
            width: 8px;
        }
        ::-webkit-scrollbar-track {
            background: #1f2937;
        }
        ::-webkit-scrollbar-thumb {
            background: #4b5563;
            border-radius: 4px;
        }
        ::-webkit-scrollbar-thumb:hover {
            background: #6b7280;
        }
        .term-description strong {
            color: #67e8f9; /* cyan-300 */
            font-weight: 600;
        }
        .term-description code {
            background-color: #374151; /* gray-700 */
            color: #f3f4f6; /* gray-100 */
            padding: 0.1em 0.3em;
            border-radius: 4px;
            font-size: 0.9em;
        }
        .detailed-explanation strong, .detailed-explanation b {
            color: #67e8f9;
        }
        .detailed-explanation ul {
            list-style-type: disc;
            margin-left: 1.5rem;
            margin-top: 0.5rem;
            margin-bottom: 0.5rem;
        }
        .detailed-explanation li {
             margin-bottom: 0.25rem;
        }
         .detailed-explanation h4 {
            font-size: 1.1rem;
            font-weight: bold;
            color: #93c5fd; /* blue-300 */
            margin-top: 1rem;
            border-bottom: 1px solid #374151;
            padding-bottom: 0.25rem;
        }
    </style>
</head>
<body class="bg-gray-900 text-gray-200">

    <div class="container mx-auto p-4 md:p-8">
        <!-- ヘッダー部分 -->
        <header class="text-center mb-8">
            <h1 class="text-3xl md:text-4xl font-bold text-cyan-400 mb-2">G検定 最強チートシート 🚀</h1>
            <p class="text-gray-400">全用語の詳細解説つき！【最終決定版】</p>
        </header>

        <!-- 検索・フィルタリング部分 -->
        <div class="sticky top-0 z-10 bg-gray-900/80 backdrop-blur-md py-4 mb-8">
            <div class="max-w-5xl mx-auto">
                <!-- 検索ボックス -->
                <input type="text" id="searchInput" placeholder="🔍  検索キーワードを入力 (例: 混合行列, Adam)" class="w-full p-3 bg-gray-800 border-2 border-gray-700 rounded-lg focus:ring-2 focus:ring-cyan-500 focus:border-cyan-500 transition-all text-white placeholder-gray-500">
                
                <!-- カテゴリフィルター -->
                <div id="categoryFilters" class="flex flex-wrap justify-center gap-2 mt-4">
                    <button class="filter-btn active" data-category="all">すべて</button>
                    <button class="filter-btn" data-category="歴史・人物">歴史・人物</button>
                    <button class="filter-btn" data-category="機械学習">機械学習</button>
                    <button class="filter-btn" data-category="ディープラーニング">ディープラーニング</button>
                    <button class="filter-btn" data-category="データサイエンス・統計">DS・統計</button>
                    <button class="filter-btn" data-category="ハードウェア・インフラ">HW・インフラ</button>
                    <button class="filter-btn" data-category="法律・倫理">法律・倫理</button>
                    <button class="filter-btn" data-category="応用分野">応用分野</button>
                </div>
            </div>
        </div>

        <!-- 用語リスト -->
        <main id="termList" class="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 xl:grid-cols-3 gap-6">
            <!-- JavaScriptによって用語カードがここに挿入されます -->
        </main>

        <!-- 項目が見つからない場合のメッセージ -->
        <div id="noResults" class="hidden text-center py-16">
            <p class="text-2xl text-gray-500">😢</p>
            <p class="text-xl text-gray-500 mt-2">該当する用語が見つかりませんでした。</p>
            <p class="text-gray-600 mt-1">検索キーワードやカテゴリを変えてみてください。</p>
        </div>

    </div>

    <script>
        const termsData = [
            // --- 歴史・人物 ---
            { term: 'アラン・チューリング', category: '歴史・人物', description: '「計算機科学の父」「人工知能の父」と呼ばれる。機械が知的かどうかを判定する<strong>【活用例】</strong>「チューリングテスト」を提唱。第二次世界大戦中、ドイツの暗号機エニグマの解読に貢献したことでも知られる。', detailed: `<h4>アラン・チューリング 詳細解説</h4><p>G検定では「AIの父」として必ず問われる人物です。彼が提唱した「チューリングテスト」は、機械に知能があるかを判定する思考実験で、AIの哲学的な議論の基礎となりました。また、計算可能なものはすべて「チューリングマシン」という仮想機械で実行できるという概念も提唱し、これが現代のコンピュータの理論的基礎となっています。</p>` },
            { term: 'ジョン・マッカーシー', category: '歴史・人物', description: '1956年のダートマス会議で「人工知能(Artificial Intelligence)」という言葉を初めて使用した人物。<strong>【活用例】</strong>AI研究用のプログラミング言語LISPを開発。', detailed: `<h4>ジョン・マッカーシー 詳細解説</h4><p>1956年に開催された「ダートマス会議」の名付け親であり、この会議で初めて「人工知能(AI)」という学術分野を提唱した中心人物です。そのため「AIの父」とも呼ばれます。また、AI研究で広く使われたプログラミング言語「LISP」を開発したことでも知られています。</p>` },
            { term: 'マービン・ミンスキー', category: '歴史・人物', description: 'AI研究の創始者の一人。パーセプトロンの限界（線形分離不可能な問題は解けない）を指摘し、第一次AIブームの終焉に影響を与えた。<strong>【活用例】</strong>知識を表現するためのフレーム理論を提唱。', detailed: `<h4>マービン・ミンスキー 詳細解説</h4><p>ダートマス会議に参加したAI研究の創始者の一人です。シーモア・パパートと共に著書「パーセプトロン」で、単純パーセプトロンの限界（XORのような線形分離不可能な問題が解けないこと）を数学的に証明し、第一次AIブームの終焉を招いたとされています。一方で、知識を構造的に表現する「フレーム理論」を提唱し、その後の知識ベースAIの研究に大きな影響を与えました。</p>` },
            { term: 'アーサー・サミュエル', category: '歴史・人物', description: '「機械学習」という言葉の生みの親とされる人物。<strong>【活用例】</strong>自身が作ったチェッカープログラムに自己学習機能を持たせ、人間以上の強さを実現した。', detailed: `<h4>アーサー・サミュエル 詳細解説</h4><p>IBMの研究者で、機械学習分野のパイオニアです。1959年に発表したチェッカーのプログラムは、自己対戦を通じて学習し、やがて人間のトッププレイヤーを打ち負かすレベルに達しました。彼自身が「明示的にプログラムすることなく学習する能力をコンピュータに与える研究分野」と定義したことが、「機械学習」という言葉の起源とされています。</p>` },
            { term: 'フランク・ローゼンブラット', category: '歴史・人物', description: 'ニューラルネットワークの源流である「パーセプトロン」を考案した心理学者・計算機科学者。', detailed: `<h4>フランク・ローゼンブラット 詳細解説</h4><p>アメリカの心理学者・計算機科学者で、1957年に「パーセプトロン」を発表しました。これは人間の脳の神経細胞の働きを模倣したモデルで、パターン認識の能力を持っていました。現代のニューラルネットワークの直接の祖先であり、AI研究の初期における重要なマイルストーンです。</p>` },
            { term: 'ジェフリー・ヒントン', category: '歴史・人物', description: '「ディープラーニングの父」の一人。<strong>【活用例】</strong>誤差逆伝播法の研究や、2012年の画像認識コンテストILSVRCでAlexNetを開発し圧勝。第三次AIブームの立役者。', detailed: `<h4>ジェフリー・ヒントン 詳細解説</h4><p>2012年の画像認識コンテストILSVRCで、自身らが開発したCNNモデル「AlexNet」で圧勝し、第三次AIブームの火付け役となりました。「誤差逆伝播法」を広く普及させ、ディープラーニングの学習を可能にした功績も非常に大きいです。ヤン・ルカン、ヨシュア・ベンジオと共に2018年のチューリング賞を受賞しました。</p>` },
            { term: 'ヤン・ルカン', category: '歴史・人物', description: '「ディープラーニングの父」の一人。畳み込みニューラルネットワーク(CNN)の生みの親。<strong>【活用例】</strong>手書き文字認識システムLeNetを開発し、銀行のATMでの手書き小切手の数字読み取りなどに活用された。', detailed: `<h4>ヤン・ルカン 詳細解説</h4><p>手書き文字認識で高い性能を発揮したCNNモデル「LeNet」の開発者として有名です。畳み込み層とプーリング層を組み合わせるというCNNの基本構造を確立しました。現在はMeta社(旧Facebook)のチーフAIサイエンティストを務めています。</p>` },
            { term: 'ヨシュア・ベンジオ', category: '歴史・人物', description: '「ディープラーニングの父」の一人。確率的勾配降下法や再帰型ニューラルネットワーク(RNN)の研究で知られる。', detailed: `<h4>ヨシュア・ベンジオ 詳細解説</h4><p>特に自然言語処理分野における、単語のベクトル表現（分散表現）や、RNN、Attention機構などの研究で大きな功績があります。AIの倫理的な側面にも積極的に発言していることでも知られています。</p>` },
            { term: 'レイ・カーツワイル', category: '歴史・人物', description: '未来学者。「シンギュラリティ(技術的特異点)」を提唱し、2045年にAIが人間の知能を超えると予測していることで有名。', detailed: `<h4>レイ・カーツワイル 詳細解説</h4><p>「シンギュラリティ」という言葉を一般に広めた人物として重要です。「収穫加速の法則」を提唱し、技術の進化は直線的ではなく指数関数的に加速すると主張しました。現在はGoogleでAI開発の責任者を務めています。</p>` },
            { term: 'ジョン・サール', category: '歴史・人物', description: '「強いAI」と「弱いAI」という考え方を提唱。<strong>【活用例】</strong>コンピュータが真に知性を持つことはないとする思考実験「中国語の部屋」で知られる。', detailed: `<h4>ジョン・サール 詳細解説</h4><p>「中国語の部屋」は、「記号をルール通りに処理すること」と「真に意味を理解すること」は違うと主張する思考実験です。AIの能力を議論する上で頻出のトピックです。「強いAI（意識を持つAI）」と「弱いAI（便利な道具としてのAI）」の区別も重要です。</p>` },
            { term: 'ロドニー・ブルックス', category: '歴史・人物', description: '従来の記号的AIを批判し、「包摂アーキテクチャ」という行動ベースのAIを提唱。知能は身体性を伴って環境との相互作用の中で生まれるとした。ロボット「ルンバ」の開発者としても有名。', detailed: `<h4>ロドニー・ブルックス 詳細解説</h4><p>マサチューセッツ工科大学の教授で、ロボット工学の権威です。従来の、世界を記号でモデル化してから行動計画を立てるAI（記号接地AI）を批判しました。そして、シンプルな反射的な行動の組み合わせ（包摂アーキテクチャ）によって、複雑なタスクをこなす自律ロボットが実現できると主張しました。この考えは、お掃除ロボット「ルンバ」の開発に繋がりました。</p>` },
            { term: 'ダートマス会議', category: '歴史・人物', description: '1956年に開催された、AI研究の出発点とされる歴史的な会議。ジョン・マッカーシーによって「人工知能」という言葉が初めて公に使われた。', detailed: `<h4>ダートマス会議 詳細解説</h4><p>1956年に開催されたこの会議には、ジョン・マッカーシー、マービン・ミンスキー、クロード・シャノンなど、後のAI研究を牽引する多くの科学者が参加しました。「人工知能」という学問分野がここから始まった、という歴史的な意義を理解しておくことが重要です。</p>` },
            { term: 'AIの冬の時代', category: '歴史・人物', description: 'AI研究に対する期待が大きすぎた反動で、研究資金が打ち切られるなどした停滞期のこと。1970年代中頃〜と1980年代後半〜の2回あったとされる。', detailed: `<h4>AIの冬の時代 詳細解説</h4><p>ブームと停滞期を繰り返してきたのがAIの歴史です。第一次ブームは単純パーセプトロンの限界が露呈したこと、第二次ブームはエキスパートシステムの限界が明らかになったことなどが原因で終焉を迎えました。このような歴史的背景を知ることで、現在の第三次AIブームを相対的に理解できます。</p>` },
            { term: 'エキスパートシステム', category: '歴史・人物', description: '第二次AIブームの中心となった技術。専門家の知識をルールとしてコンピュータに組み込み、専門家のように振る舞うシステム。<strong>【活用例】</strong>医療診断支援システムMYCINなど。知識の獲得（知識のボトルネック）が課題となった。', detailed: `<h4>エキスパートシステム 詳細解説</h4><p>専門家の知識を「if-thenルール」のような形式でコンピュータに記述し、特定の分野の問題解決を行うシステムです。第二次AIブームを牽引しましたが、専門家の知識を網羅的にルール化することの困難さ（知識獲得のボトルネック）や、例外的な状況に対応できないという問題に直面し、ブームは下火になりました。</p>` },

            // --- 機械学習 ---
            { term: '教師あり学習', category: '機械学習', description: '正解ラベル(y)付きの入力データ(x)を使い、xからyを予測する関数f(x)を学習する手法。<strong>【技術詳細】</strong>学習時には、予測値と正解値の誤差を定義した「損失関数」（回帰では平均二乗誤差、分類では交差エントロピー誤差など）を最小化するようにモデルのパラメータを更新する。', detailed: `<h4>教師あり学習 詳細解説</h4><p>入力データ（説明変数）と、それに対応する正解ラベル（目的変数）のペアを学習データとして与え、未知の入力データに対する正解を予測するモデルを構築する手法です。タスクは大きく「回帰」と「分類」に分けられます。</p><h4>G検定でのポイント</h4><ul><li><strong>回帰:</strong> 目的変数が連続値（例：株価、気温、家の価格など）。</li><li><strong>分類:</strong> 目的変数がカテゴリ（例：スパムか否か、犬か猫か、病気の種類など）。</li></ul><p>この2つの違いと具体例をしっかり押さえることが重要です。</p>` },
            { term: '教師なし学習', category: '機械学習', description: '正解ラベルがないデータから、その背後にある構造やパターンを発見する手法。<strong>【技術詳細】</strong>クラスタリング(k-means法)、次元削減(主成分分析PCA)、アソシエーション分析(Apriori)などが代表的なアルゴリズム。', detailed: `<h4>教師なし学習 詳細解説</h4><p>正解ラベルがないデータから、データそのものの構造、パターン、関係性などを見つけ出す手法です。データの背後にある本質的な構造を明らかにすることを目的とします。</p><h4>G検定でのポイント</h4><ul><li><strong>クラスタリング:</strong> データを似たもの同士のグループに分ける手法（例：顧客セグメンテーション）。k-means法が代表的。</li><li><strong>次元削減:</strong> データの次元（特徴量の数）を減らす手法（例：アンケート結果の要約）。主成分分析(PCA)が代表的。</li></ul><p>教師あり学習との根本的な違い（正解データの有無）を理解しましょう。</p>` },
            { term: '強化学習', category: '機械学習', description: 'エージェントが環境内で試行錯誤し、報酬を最大化する行動方針(Policy)を学習する手法。<strong>【技術詳細】</strong>「マルコフ決定過程」として定式化される。価値関数を学習するQ学習や、方策を直接学習する方策勾配法などがある。', detailed: `<h4>強化学習 詳細解説</h4><p>強化学習は、機械学習の一分野で、ある<strong>環境(Environment)</strong>の中にいる<strong>エージェント(Agent)</strong>が、試行錯誤を通じて<strong>累積報酬(Cumulative Reward)</strong>を最大化するような<strong>方策(Policy)</strong>、つまり行動のルールを学習する手法です。</p><p>G検定では、以下のキーワードが重要になります。</p><ul><li><strong>エージェント:</strong> 環境の中で行動する主体（例：ゲームのキャラクター、ロボット）。</li><li><strong>環境:</strong> エージェントが行動する世界そのもの。</li><li><strong>行動(Action):</strong> エージェントが取りうる選択肢。</li><li><strong>状態(State):</strong> ある時点での環境の状況。</li><li><strong>報酬(Reward):</strong> エージェントの行動の結果として得られるフィードバック。良い行動には正の報酬、悪い行動には負の報酬（罰）が与えられます。</li><li><strong>方策(Policy):</strong> ある状態で、どの行動を取るかを決める戦略やルールのこと。</li><li><strong>価値関数(Value Function):</strong> ある状態や、ある状態である行動を取った場合に、将来的に得られる累積報酬の期待値。これを最大化することが目標となります。</li></ul><h4>G検定でのポイント</h4><p>教師あり学習や教師なし学習との違いを明確に理解することが重要です。強化学習は「明確な正解データ」がない代わりに、「行動の結果としての報酬」を頼りに学習を進めます。囲碁AIのAlphaGoが代表例としてよく挙げられます。</p>` },
            { term: '半教師あり学習', category: '機械学習', description: '少量のラベル付きデータと大量のラベルなしデータを組み合わせて学習する手法。<strong>【技術詳細】</strong>ラベル付けのコストが高い場合に有効。ラベルなしデータでデータの分布を学習し、ラベル付きデータで精度を上げる。', detailed: `<h4>半教師あり学習 詳細解説</h4><p>大量のデータは手に入るものの、そのすべてに正解ラベルを付ける作業（アノテーション）には膨大なコストがかかる、という現実的な課題に対応するための手法です。大量のラベルなしデータを使ってデータの全体的な構造や分布を掴み、少量のラベル付きデータでその解釈を学習させる、といったアプローチを取ります。</p><h4>G検定でのポイント</h4><p>教師あり・教師なし・強化学習との違いを理解することが重要です。ラベル付けコストが高い現実世界の課題（例：大量の画像の中から特定の種類の画像だけを分類したいが、全てにラベルを付けるのは大変）を解決するアプローチとして注目されています。</p>` },
            { term: '自己教師あり学習', category: '機械学習', description: 'データ自身から擬似的なラベルを自動生成し、それを解くタスク（Pretext Task）を学習する手法。<strong>【技術詳細】</strong>BERTのMasked LMや、画像の一部を予測させるタスクが例。大量のラベルなしデータから特徴表現を学習できるため、転移学習の事前学習で広く使われる。', detailed: `<h4>自己教師あり学習 詳細解説</h4><p>人間が正解ラベルを与える代わりに、データ自身から学習の「問題」と「答え」を自動的に作り出す学習パラダイムです。例えば、文章の一部を隠し（問題）、それを予測させる（答え）。あるいは、画像の一部を切り抜いて、その位置を当てさせる、などです。このプロセスを通じて、モデルはデータの背後にある本質的な特徴表現（意味など）を学習します。</p><h4>G検定でのポイント</h4><p>TransformerベースのBERTやGPTといった近年の大規模言語モデルの成功の根幹を支える技術です。大量のラベルなしデータ（Web上のテキストなど）から、AIが自ら問題を作って解くことで、汎用的な言語能力を獲得できるという点が画期的です。</p>` },
            { term: '回帰 (Regression)', category: '機械学習', description: '連続的な数値を予測するタスク。<strong>【技術詳細】</strong>線形回帰、多項式回帰、サポートベクター回帰(SVR)などがある。評価指標は平均二乗誤差(MSE)や平均絶対誤差(MAE)が用いられる。', detailed: `<h4>回帰 詳細解説</h4><p>入力されたデータ（説明変数）から、連続する数値（目的変数）を予測するタスクです。例えば、過去の販売実績データから明日の売上を予測したり、家の広さや築年数から価格を予測したりします。</p><h4>G検定でのポイント</h4><p>「分類」との違いを明確に理解することが重要です。連続的な数値を予測するタスクであり、代表的なアルゴリズムとして線形回帰、決定木、ランダムフォレストなどがあります。</p>` },
            { term: '分類 (Classification)', category: '機械学習', description: 'データがどのカテゴリに属するかを予測するタスク。<strong>【技術詳細】</strong>2値分類（ロジスティック回帰）と多クラス分類がある。評価指標は正解率、適合率、再現率、F値、AUCなどが用いられる。', detailed: `<h4>分類 詳細解説</h4><p>入力されたデータが、あらかじめ定義されたどのクラス（カテゴリ）に属するかを予測するタスクです。例えば、メールの文面から「迷惑メール」か「通常メール」かを判定したり、動物の画像から「犬」「猫」「鳥」のどれかを判定したりします。</p><h4>G検定でのポイント</h4><p>「回帰」との違いを明確に理解することが重要です。カテゴリを予測するタスクであり、2値分類（例：迷惑メールか否か）と多クラス分類（例：犬、猫、鳥のどれか）があります。</p>` },
            { term: 'ロジスティック回帰', category: '機械学習', description: '分類問題で用いられる基本的な手法。ある事象が発生する確率を予測する。<strong>【技術詳細】</strong>線形回帰の出力をシグモイド関数に通すことで、出力を0〜1の確率に変換する。線形分離可能な問題に使われる。', detailed: `<h4>ロジスティック回帰 詳細解説</h4><p>2値分類問題で最も基本となるアルゴリズムの一つです。入力されたデータがあるクラスに属する確率を予測します。この確率が、事前に決めた閾値（例: 0.5）を超えればそのクラスに属すると判断します。</p><h4>G検定でのポイント</h4><p>名前は「回帰」とついていますが、「分類」のための手法である点に注意が必要です。単純で解釈しやすいため、多くの分類問題のベースラインとして利用されます。</p>` },
            { term: 'k-NN法 (k近傍法)', category: '機械学習', description: '分類や回帰に用いられる単純な手法。未知のデータと最も近いk個の既知のデータを見て、多数決でクラスを決定する。<strong>【技術詳細】</strong>怠惰学習（lazy learning）の一種で、学習フェーズがほぼなく、予測時に計算コストがかかる。kの値をどう設定するかが重要。', detailed: `<h4>k-NN法 詳細解説</h4><p>非常に直感的でシンプルなアルゴリズムです。新しいデータが入力されると、学習データの中から最も「近い」データをk個探し、それらの多数決によってクラスを決定します（分類の場合）。「近さ」はユークリッド距離などが用いられます。</p><h4>G検定でのポイント</h4><p>アルゴリズムが非常に単純で理解しやすいのが特徴です。一方で、データ量が増えると予測に時間がかかるという欠点があります。「怠惰学習」または「事例ベース学習」の代表例として覚えておきましょう。</p>` },
            { term: '過学習 (Overfitting)', category: '機械学習', description: '訓練データに適合しすぎて未知のデータへの予測精度が低い状態。<strong>【技術詳細】</strong>モデルの表現力が高すぎる（高バリアンス）か、訓練データが少ない場合に発生。訓練誤差は小さいが、テスト誤差が大きいのが特徴。「バイアスとバリアンスのトレードオフ」の観点から理解される。', detailed: `<h4>過学習 詳細解説</h4><p>モデルが訓練データに過剰に適合し、データに含まれるノイズまで学習してしまった状態です。その結果、訓練データに対する正解率は非常に高いのに、未知の新しいデータ（テストデータ）に対しては全く予測が当たらなくなります。これを「汎化性能が低い」と表現します。</p><h4>G検定でのポイント</h4><p>過学習はモデルの「汎化性能」が低い状態を指します。これを防ぐための技術（正則化、ドロップアウト、データ拡張など）とセットで問われることが多いです。「バイアスとバリアンスのトレードオフ」の観点から、高バリアンスな状態であることも理解しておきましょう。</p>` },
            { term: '正則化 (Regularization)', category: '機械学習', description: '過学習を防ぐため、モデルの複雑さにペナルティを課す手法。<strong>【技術詳細】</strong>損失関数に正則化項を追加する。L1正則化(Lasso)は一部の重みを0にし特徴量選択の効果を持つ。L2正則化(Ridge)は重みが大きくなるのを防ぐ。', detailed: `<h4>正則化 詳細解説</h4><p>モデルのパラメータ（重み）が極端に大きな値を取ることを抑制することで、モデルが複雑になりすぎるのを防ぎ、過学習を抑制する手法です。損失関数に、パラメータの大きさに対するペナルティ項を追加することで実現します。</p><h4>G検定でのポイント</h4><p>過学習を防ぐための代表的な手法です。L1正則化とL2正則化の違い（L1は不要な特徴量の重みを0にするため特徴量選択の効果がある）を理解しておくことが重要です。</p>` },
            { term: 'サポートベクターマシン (SVM)', category: '機械学習', description: 'マージン最大化という考えに基づき、高い汎化性能を持つ分類器。<strong>【技術詳細】</strong>「カーネルトリック」を用いることで、線形分離不可能なデータも高次元空間に写像して線形分離を可能にする（多項式カーネル、RBFカーネルなど）。', detailed: `<h4>サポートベクターマシン 詳細解説</h4><p>データをクラス分けする際に、各クラスのデータから最も近い位置にあるデータ（サポートベクター）との距離（マージン）が最大になるような境界線を引くことで、未知のデータに対する高い分類性能（汎化性能）を目指すアルゴリズムです。</p><h4>G検定でのポイント</h4><p>「マージン最大化」と「カーネルトリック」が最重要キーワードです。かつては非常に高い性能を誇る分類器として、ディープラーニング以前の時代に広く使われていました。</p>` },
            { term: 'アンサンブル学習', category: '機械学習', description: '複数の弱学習器を組み合わせ、より強力なモデルを構築する手法。<strong>【技術詳細】</strong>代表的な手法に、並列に学習させる「バギング」（ランダムフォレスト）と、逐次的に学習させる「ブースティング」（勾配ブースティング）がある。', detailed: `<h4>アンサンブル学習 詳細解説</h4><p>単体ではそれほど性能が高くない複数のモデル（弱学習器）を組み合わせることで、全体として非常に高性能なモデルを作り出す手法です。「三人寄れば文殊の知恵」を実践するアプローチと言えます。</p><h4>G検定でのポイント</h4><p>単一のモデルよりも高い精度と安定性を得られるため、実際のデータ分析コンペティション（Kaggleなど）で頻繁に利用されます。「バギング」「ブースティング」という代表的な2つのアプローチの違いを理解することが重要です。</p>` },
            { term: 'ハイパーパラメータ', category: '機械学習', description: '機械学習モデルの学習プロセス自体を制御するパラメータ。モデルがデータから学習するパラメータ（重みなど）とは区別される。<strong>【技術詳細】</strong>学習率、正則化の強さ、決定木の深さ、k-NNのkの値などが該当。グリッドサーチやベイジアン最適化などの手法で最適な値を探す。', detailed: `<h4>ハイパーパラメータ 詳細解説</h4><p>モデルの性能を大きく左右する、人間が経験や勘、あるいは自動探索手法に基づいて設定する必要がある「外部の」パラメータです。例えば、料理における「火加減」や「調理時間」のようなもので、この設定次第で料理の出来栄えが大きく変わります。</p><h4>G検定でのポイント</h4><p>モデル自身が学習して決める「パラメータ（重みやバイアス）」とは区別される、人間が事前に設定するパラメータであるという点を理解しましょう。この調整作業を「ハイパーパラメータチューニング」と呼びます。</p>` },

            // --- ディープラーニング ---
            { term: 'ニューラルネットワーク', category: 'ディープラーニング', description: '脳の神経細胞を模倣した数理モデル。重み(w)とバイアス(b)を持つ多数のニューロン（ノード）が層状に結合している。<strong>【技術詳細】</strong>入力信号の重み付き和を活性化関数で非線形変換し、次の層に出力する。', detailed: `<h4>ニューラルネットワーク 詳細解説</h4><p>人間の脳の神経細胞（ニューロン）がシナプスで繋がり、情報をやり取りする仕組みを数理的に模倣したモデルです。入力層、中間層（隠れ層）、出力層という複数の層から成り立ち、層と層の間はノード（ニューロン）が結合されています。この結合の強さが「重み」パラメータです。</p><h4>G検定でのポイント</h4><p>入力層、中間層（隠れ層）、出力層の3つの層から構成されるのが基本です。中間層が多層になったものがディープニューラルネットワーク（DNN）であり、ディープラーニングの中核をなします。</p>` },
            { term: '活性化関数', category: 'ディープラーニング', description: 'ニューロンの発火を模倣し、ネットワークに非線形性をもたらす関数。<strong>【技術詳細】</strong>初期によく使われたシグモイド関数やtanh関数は勾配消失問題を起こしやすい。現在では<code>ReLU(max(0, x))</code>が主流。出力層では、多クラス分類の確率出力にソフトマックス関数が使われる。', detailed: `<h4>活性化関数 詳細解説</h4><p>ニューラルネットワークの各ニューロンにおいて、入力信号の合計値をどのように出力信号に変換するかを決定する関数です。この関数が非線形であることにより、ネットワークは複雑なパターンを学習できるようになります。</p><h4>G検定でのポイント</h4><p>活性化関数がなければ、ニューラルネットワークはただの線形変換の積み重ねとなり、複雑なパターンを学習できません。非線形な関数を導入することが、モデルの表現力を高める上で不可欠です。ReLUが現在最も一般的に使われる理由（勾配消失問題の緩和）も押さえておきましょう。</p>` },
            { term: '誤差逆伝播法', category: 'ディープラーニング', description: '出力と正解の誤差を、微分係数の連鎖律(Chain Rule)を用いて、出力層から入力層へ逆方向に伝播させ、各層の重みを効率的に更新するアルゴリズム。', detailed: `<h4>誤差逆伝播法 詳細解説</h4><p>ニューラルネットワークの学習において、予測結果と正解データの誤差（損失）を計算し、その誤差を最小化するように各層の重みパラメータを更新するための効率的なアルゴリズムです。出力層側から入力層側へと、微分を連鎖的に計算していくことで、各パラメータが誤差にどれだけ貢献したかを算出します。</p><h4>G検定でのポイント</h4><p>ディープラーニングモデルの学習における最も基本的なアルゴリズムです。計算された誤差を微分によって各層のパラメータにフィードバックし、勾配降下法によってパラメータを更新していく、という流れを理解しましょう。</p>` },
            { term: '最適化アルゴリズム (Optimizer)', category: 'ディープラーニング', description: '損失関数を最小化するために、モデルの重みを効率的に更新する手法。<strong>【技術詳細】</strong><code>SGD</code>（確率的勾配降下法）が基本。<code>Momentum</code>は慣性を加えることで収束を速める。<code>Adam</code>は各パラメータに対して適応的に学習率を調整する手法で、現在最も広く使われている。', detailed: `<h4>最適化アルゴリズム 詳細解説</h4><p>誤差逆伝播法で計算された勾配を元に、どのように重みを更新すれば最も効率的に損失関数を最小化できるかを決めるアルゴリズムです。坂道を下る方法に様々な戦略（一歩の大きさ、過去の勢いの利用など）があるように、オプティマイザにも様々な種類があります。</p><h4>G検定でのポイント</h4><p>様々な種類がありますが、現在は「Adam」がデファクトスタンダードとして広く利用されています。それぞれのアルゴリズムが、勾配降下法をどのように改良しているのか（例：Momentumは慣性、Adamは適応的な学習率）を大まかに把握しておくと良いでしょう。</p>` },
            { term: '学習率 (Learning Rate)', category: 'ディープラーニング', description: '重みを更新する際のステップ幅を制御するハイパーパラメータ。<strong>【技術詳細】</strong>大きすぎると学習が発散し、小さすぎると収束が非常に遅くなる。学習率を徐々に小さくするスケジューリング手法（学習率減衰）も一般的。', detailed: `<h4>学習率 詳細解説</h4><p>最適化アルゴリズムが重みを更新する際の「歩幅」を決めるハイパーパラメータです。学習率が大きいと、大胆にパラメータを更新しますが、最適解を通り過ぎてしまう（発散する）リスクがあります。逆に小さいと、慎重に更新するため時間はかかりますが、より良い解にたどり着く可能性が高まります。</p><h4>G検定でのポイント</h4><p>モデルの学習がうまくいくかを左右する、最も重要なハイパーパラメータの一つです。学習率を最初大きく設定し、学習が進むにつれて徐々に小さくしていく「学習率スケジューリング」というテクニックもよく使われます。</p>` },
            { term: 'ドロップアウト (Dropout)', category: 'ディープラーニング', description: '過学習を抑制するための正則化手法。<strong>【技術詳細】</strong>学習時に、各ニューロンを一定の確率でランダムに無効化（ドロップアウト）する。これにより、特定のニューロンへの過度な依存を防ぎ、アンサンブル学習に似た効果が得られる。', detailed: `<h4>ドロップアウト 詳細解説</h4><p>学習の各ステップで、ニューラルネットワークの一部のニューロンをランダムに「無視」して学習を進める手法です。これにより、モデルは特定のニューロンの働きに過度に依存しなくなり、より頑健な特徴を学習するようになります。結果として過学習が抑制されます。</p><h4>G検定でのポイント</h4><p>非常に強力な正則化手法であり、過学習対策として頻繁に利用されます。学習時のみ適用され、推論（予測）時にはすべてのニューロンを使用するという点も重要です。</p>` },
            { term: '勾配消失/爆発問題', category: 'ディープラーニング', description: '深いネットワークで誤差逆伝播を行う際、勾配が層を遡るごとに指数関数的に小さくなる（消失）か、大きくなる（爆発）問題。<strong>【技術詳細】</strong>消失すると学習が停滞し、爆発すると学習が不安定になる。ReLU、ResNet、LSTM、勾配クリッピングなどが対策として知られる。', detailed: `<h4>勾配消失/爆発問題 詳細解説</h4><p>誤差逆伝播法では、出力層から入力層に向かって勾配を掛け合わせていきます。層が深くなると、この勾配の値が1より小さい場合はどんどん0に近づき（消失）、1より大きい場合はどんどん巨大な値になってしまいます（爆発）。これにより、入力層に近い層のパラメータがほとんど更新されなくなったり、学習が不安定になったりします。</p><h4>G検定でのポイント</h4><p>特に深いネットワーク（層が多いモデル）で顕著になる問題です。この問題を解決するために、活性化関数の工夫（ReLU）、バッチ正規化、残差接続（ResNet）、ゲート付きRNN（LSTM, GRU）などの様々な技術が開発されました。</p>` },
            { term: 'バッチ正規化', category: 'ディープラーニング', description: 'ミニバッチ単位で、層への入力データの分布を平均0、分散1に正規化する手法。<strong>【技術詳細】</strong>各層の入力分布の変動（内部共変量シフト）を抑制し、学習の安定化・高速化、正則化の効果をもたらす。', detailed: `<h4>バッチ正規化 詳細解説</h4><p>学習が進むにつれて各層の出力（＝次の層の入力）の分布が変化してしまう「内部共変量シフト」という問題を解決するための手法です。ミニバッチごとにデータの分布を正規化することで、学習を安定させ、学習率を高く設定できるようになり、結果として学習が高速化します。</p><h4>G検定でのポイント</h4><p>学習の高速化・安定化に大きく貢献する重要な技術です。CNNの畳み込み層や全結合層の後に挿入されるのが一般的です。</p>` },
            { term: 'CNN (畳み込みニューラルネットワーク)', category: 'ディープラーニング', description: '主に画像認識で使われるモデル。<strong>【技術詳細】</strong>「畳み込み層」でフィルタ（カーネル）をスライドさせ特徴マップを抽出し、「プーリング層」で特徴を圧縮する。これにより、画像の局所的な特徴と位置不変性を獲得できる。', detailed: `<h4>CNN 詳細解説</h4><p>画像のようなグリッド構造を持つデータに対して非常に高い性能を発揮するモデルです。画像全体ではなく、フィルタと呼ばれる小さな領域で画像を見る「畳み込み層」と、特徴の位置ずれを吸収する「プーリング層」を交互に重ねるのが特徴です。</p><h4>G検定でのポイント</h4><p>「畳み込み層」と「プーリング層」がセットで使われることが特徴です。画像データに対して圧倒的な性能を発揮し、第三次AIブームの火付け役となりました。LeNet, AlexNet, VGG, ResNetといった代表的なモデル名と、その進化の歴史も重要です。</p>` },
            { term: 'RNN (再帰型ニューラルネットワーク)', category: 'ディープラーニング', description: '順序性のあるデータを扱うのが得意なモデル。<strong>【技術詳細】</strong>過去の情報を内部状態（隠れ状態）<code>h_t</code>として保持し、現在の入力<code>x_t</code>と過去の状態<code>h_{t-1}</code>から次の状態<code>h_t</code>を計算するループ構造を持つ。長期の依存関係の学習が苦手。', detailed: `<h4>RNN 詳細解説</h4><p>過去の情報を記憶し、現在の判断に利用できるという特徴を持つニューラルネットワークです。ネットワーク内部にループ構造を持っており、時系列に沿って情報を伝播させていきます。これにより、単語の並び順が重要な自然言語や、株価のような時系列データの扱いに適しています。</p><h4>G検定でのポイント</h4><p>時系列データや自然言語のように、データの順序が意味を持つ場合に利用されます。ただし、長期的な依存関係の学習が苦手（長期依存性問題）という欠点があり、それを克服するためにLSTMやGRUが開発されました。</p>` },
            { term: 'LSTM (Long Short-Term Memory)', category: 'ディープラーニング', description: 'RNNの長期依存性問題を解決するために考案されたモデル。<strong>【技術詳細】</strong>情報を忘れるか保持するかを制御する「忘却ゲート」、新しい情報を追加する「入力ゲート」、何を出力するかを制御する「出力ゲート」という3つのゲート構造を導入した。', detailed: `<h4>LSTM 詳細解説</h4><p>RNNの一種で、長期的な情報をうまく保持できるように改良されたモデルです。「セルの状態」と呼ばれる長期記憶用の経路と、「忘却ゲート」「入力ゲート」「出力ゲート」という3つのゲートを導入することで、過去の重要な情報だけを選択的に記憶し、不要な情報は忘れるという制御を可能にしました。</p><h4>G検定でのポイント</h4><p>RNNの長期依存性問題を解決したモデルとして非常に重要です。「ゲート」という特殊な構造によって、情報の取捨選択を可能にした点が画期的です。Seq2Seqモデルなどで広く利用されてきました。</p>` },
            { term: 'GRU (Gated Recurrent Unit)', category: 'ディープラーニング', description: 'LSTMを簡略化したモデル。<strong>【技術詳細】</strong>更新ゲートとリセットゲートの2つのゲートのみで構成され、LSTMよりパラメータが少なく計算効率が良い。性能はタスクによるがLSTMに匹敵することも多い。', detailed: `<h4>GRU 詳細解説</h4><p>LSTMと同様にゲート機構を持つRNNの一種ですが、ゲートの数を2つ（更新ゲート、リセットゲート）に減らし、セル状態を持たないなど、よりシンプルな構造になっています。これにより、計算コストが低く、学習が速くなる傾向があります。</p><h4>G検定でのポイント</h4><p>LSTMをよりシンプルな構造にしたモデルです。性能はLSTMに匹敵することが多く、計算コストが低いため、選択肢の一つとして知られています。</p>` },
            { term: 'Seq2Seq', category: 'ディープラーニング', description: 'あるシーケンス（系列）を入力として、別のシーケンスを出力するモデルの総称。<strong>【技術詳細】</strong>入力系列を固定長のベクトルに変換するエンコーダと、そのベクトルから出力系列を生成するデコーダから構成される。機械翻訳や対話システムで使われる。', detailed: `<h4>Seq2Seq 詳細解説</h4><p>エンコーダ・デコーダモデルとも呼ばれ、ある可変長の系列データを別の可変長の系列データに変換するモデルです。エンコーダRNNが入力文（例：日本語）を読み込んで一つのコンテキストベクトルに圧縮し、デコーダRNNがそのベクトルから出力文（例：英語）を生成します。</p><h4>G検定でのポイント</h4><p>エンコーダ・デコーダモデルの代表例です。入力文を一つのベクトルに押し込める部分が情報のボトルネックになりやすいという課題があり、それを解決するために「Attention機構」が考案されました。</p>` },
            { term: 'Transformer', category: 'ディープラーニング', description: '自然言語処理に革命をもたらしたモデル。<strong>【技術詳細】</strong>RNNの再帰構造を廃し、「自己注意機構(Self-Attention)」を用いて入力系列内の単語間の関連度を直接計算する。並列計算に優れ、GPTやBERTの基盤技術。', detailed: `<h4>Transformer 詳細解説</h4><p>Transformerは、2017年にGoogleが発表した論文「Attention Is All You Need」で提唱された、主に自然言語処理で使われる画期的なニューラルネットワークモデルです。</p><p>G検定で押さえるべき技術的なポイントは以下の通りです。</p><ul><li><strong>RNN/CNNの不使用:</strong> 従来の主要モデルだったRNNやCNNの再帰・畳み込み構造を一切使わず、後述するAttention機構のみで構成されている点が最大の特徴です。</li><li><strong>自己注意機構 (Self-Attention):</strong> 文章中の単語間の関連度を直接計算する仕組みです。「彼はその犬を可愛がった。なぜなら、<strong>それ</strong>はとても人懐っこかったからだ。」という文で、「それ」が「犬」を指していることを直接的に関連付けられます。</li><li><strong>並列化による高速化:</strong> RNNのように逐次的に処理する必要がないため、GPUによる並列計算の恩恵を最大限に受けることができ、非常に大規模なデータでの学習が可能になりました。</li><li><strong>位置エンコーディング (Positional Encoding):</strong> 単語の順序情報を失ってしまうAttentionの欠点を補うため、各単語の位置情報をベクトルとして加算する技術です。</li></ul><h4>G検定でのポイント</h4><p>Transformerが、その後のBERTやGPTといった大規模言語モデル(LLM)の基盤技術となったという流れは非常に重要です。自然言語処理の歴史におけるブレークスルーとして認識しておきましょう。</p>` },
            { term: 'Attention (アテンション) 機構', category: 'ディープラーニング', description: '入力系列のどの部分に「注目」すべきかを動的に学習する仕組み。<strong>【技術詳細】</strong>Query, Key, Valueという3つのベクトルを用いて、Queryと各Keyの類似度を計算し、その重みに基づいてValueの重み付き和を求める。', detailed: `<h4>Attention (アテンション) 機構 詳細解説</h4><p>Seq2Seqモデルなどで、出力系列のある単語を生成する際に、入力系列のどの単語に「注目」すればよいかの重み（Attention Weight）を動的に計算する仕組みです。これにより、長い文章でも重要な情報を失うことなく、文脈に応じた変換が可能になります。</p><h4>G検定でのポイント</h4><p>元々はSeq2Seqモデルの性能向上のために考案されましたが、Transformerではモデルの根幹をなす要素となりました。文章中のどの単語に「注目」すべきか、その重みを動的に計算するというアイデアが重要です。</p>` },
            { term: '転移学習 (Transfer Learning)', category: 'ディープラーニング', description: 'あるタスクで学習済みのモデルを別のタスクに適用する手法。<strong>【技術詳細】</strong>ImageNetで学習済みの<code>VGG16</code>や<code>ResNet</code>、大規模テキストで学習済みの<code>BERT</code>などがベースモデルとしてよく利用される。', detailed: `<h4>転移学習 詳細解説</h4><p>ある領域（ソースドメイン）で学習した知識やモデルを、別の関連する領域（ターゲットドメイン）に適用するアプローチです。例えば、大量の一般的な画像で学習したモデルは、画像の基本的な特徴（線や角、模様など）を捉える能力を獲得しています。この能力を、データが少ない専門的なタスク（例：特定の製品の不良品検知）に応用します。</p><h4>G検定でのポイント</h4><p>現代のディープラーニング開発では必須のテクニックです。巨大なデータセットで事前学習されたモデル（学習済みモデル）を利用することで、少ないデータでも高い精度のモデルを効率的に開発できます。</p>` },
            { term: 'GAN (敵対的生成ネットワーク)', category: 'ディープラーニング', description: '生成器(G)と識別器(D)を競わせることでリアルなデータを生成するモデル。<strong>【技術詳細】</strong>Gは乱数から偽データを生成し、DはGが生成したデータか本物のデータかを見分ける。GはDを騙そうと学習し、DはGを見破ろうと学習する「ミニマックスゲーム」を行う。', detailed: `<h4>GAN 詳細解説</h4><p>本物のデータそっくりのデータを生成することを目的としたモデルです。「生成器（Generator）」と「識別器（Discriminator）」という2つのネットワークを敵対的に競わせながら学習させます。生成器は偽札職人、識別器は警察官に例えられます。</p><h4>G検定でのポイント</h4><p>「生成モデル」の一種であり、そのユニークな学習方法（敵対的学習）が特徴です。高品質な画像生成能力から、ディープフェイクなどの倫理的な問題と関連付けて問われることもあります。</p>` },
            { term: 'オートエンコーダ', category: 'ディープラーニング', description: '教師なし学習の一種。データを圧縮するエンコーダと、復元するデコーダから成る。<strong>【技術詳細】</strong>入力データ自身を正解ラベルとして学習する。潜在空間の表現を学習でき、変分オートエンコーダ(VAE)はデータ生成にも応用される。', detailed: `<h4>オートエンコーダ 詳細解説</h4><p>入力データを一度、より低次元の潜在表現に圧縮（エンコード）し、その潜在表現から元のデータを復元（デコード）するように学習するニューラルネットワークです。入力データそのものを正解データとして学習するため、教師なし学習に分類されます。</p><h4>G検定でのポイント</h4><p>教師なし学習の手法であり、次元削減や異常検知に応用されます。入力データを一度低次元の潜在変数に圧縮（エンコード）し、それを元に復元（デコード）するという構造を理解しておきましょう。</p>` },
            { term: 'ResNet (Residual Network)', category: 'ディープラーニング', description: '「スキップ接続」で非常に深いネットワークの学習を可能にしたモデル。<strong>【技術詳細】</strong>層の入力が出力に直接足し合わされる「残差ブロック」を導入。これにより、ネットワークは恒等写像を学習しやすくなり、勾配消失問題が緩和され、1000層を超える学習も可能になった。', detailed: `<h4>ResNet 詳細解説</h4><p>Microsoft Researchが開発したCNNモデルです。層を深くしすぎると性能が劣化する「劣化問題」を、「スキップ接続（残差接続）」と呼ばれる構造で解決しました。これは、層の入力をその層の出力に足し合わせるという単純な仕組みで、勾配の流れをスムーズにし、非常に深いネットワークの学習を可能にしました。</p><h4>G検定でのポイント</h4><p>「スキップ接続（残差接続）」というキーワードが最重要です。この仕組みにより、それまで困難だった100層を超えるような非常に深いネットワークの学習が可能になり、画像認識の精度を大きく向上させました。</p>` },
            { term: 'BERT', category: 'ディープラーニング', description: 'Googleが開発したTransformerベースの自然言語処理モデル。<strong>【技術詳細】</strong>事前学習タスクとして、文中の単語をマスクし予測する「Masked LM」と、2文が連続しているかを予測する「Next Sentence Prediction」を用いることで、双方向の文脈を深く理解する。', detailed: `<h4>BERT 詳細解説</h4><p>Bidirectional Encoder Representations from Transformersの略。Transformerのエンコーダ部分を利用しています。最大の特徴は、文章の文脈を左から右、右から左という「双方向」から同時に理解する点です。これを実現するために、「Masked Language Model」という事前学習タスクを用いています。</p><h4>G検定でのポイント</h4><p>Transformerのエンコーダ部分を利用したモデルです。「双方向」から文脈を理解する点が画期的であり、それ以前のモデル（GPTなど）を一気に時代遅れにしました。様々な自然言語処理タスクの性能を大幅に塗り替えたモデルとして重要です。</p>` },
            { term: 'GPT (Generative Pre-trained Transformer)', category: 'ディープラーニング', description: 'OpenAIが開発した大規模言語モデル。<strong>【技術詳細】</strong>Transformerのデコーダ部分をベースにしており、膨大なテキストデータで事前学習されている。文章生成能力が非常に高く、ChatGPTの基盤技術。', detailed: `<h4>GPT 詳細解説</h4><p>Generative Pre-trained Transformerの略。Transformerのデコーダ部分をベースにしています。BERTとは異なり、文脈を「一方向（左から右）」にのみ参照して、次に来る単語を予測するタスクで学習します。これにより、非常に自然で流暢な文章を生成する能力を獲得しました。</p><h4>G検定でのポイント</h4><p>Transformerのデコーダ部分を利用したモデルです。BERTとは対照的に、次に来る単語を予測することで、非常に流暢な文章を生成することを得意としています。ChatGPTの成功により、その名が広く知られるようになりました。</p>` },
            { term: '物体検出 (Object Detection)', category: 'ディープラーニング', description: '画像内の物体の「位置」と「種類（クラス）」を同時に特定するタスク。<strong>【技術詳細】</strong><code>Faster R-CNN</code>のような2段階検出器と、<code>YOLO</code>や<code>SSD</code>のような1段階検出器がある。自動運転や防犯カメラで重要な技術。', detailed: `<h4>物体検出 詳細解説</h4><p>画像認識のタスクの一つで、画像の中に「何が（分類）」、「どこに（位置）」あるのかを特定します。位置は、通常、物体を囲む矩形（バウンディングボックス）の座標で示されます。</p><h4>G検定でのポイント</h4><p>単なる「分類」だけでなく、物体の「位置（バウンディングボックス）」も同時に予測するタスクです。自動運転における歩行者や車両の検出など、実世界での応用範囲が非常に広いです。</p>` },
            { term: 'セマンティックセグメンテーション', category: 'ディープラーニング', description: '画像をピクセル単位で分類し、各ピクセルがどのクラスに属するかを識別するタスク。<strong>【技術詳細】</strong>エンコーダ・デコーダ構造を持つ<code>FCN</code>や<code>U-Net</code>が有名。自動運転の道路領域認識や医療画像の臓器抽出などに使われる。', detailed: `<h4>セマンティックセグメンテーション 詳細解説</h4><p>画像認識タスクの中でも、最も詳細な理解を要求されるタスクの一つです。画像を構成する全てのピクセルに対して、それがどのクラスに属するのか（例：空、道路、歩行者、建物など）を分類します。</p><h4>G検定でのポイント</h4><p>「ピクセル単位の分類」であるという点が重要です。物体検出よりもさらに詳細な領域の特定が可能で、医療画像の解析や自動運転の走行可能領域の認識などに利用されます。</p>` },
            { term: 'モデル圧縮', category: 'ディープラーニング', description: '学習済みモデルのサイズを小さくし、推論を高速化する技術群。<strong>【技術詳細】</strong><code>量子化</code>（パラメータの精度を落とす）、<code>枝刈り（プルーニング）</code>（重要でない重みを削除）、<code>知識蒸留</code>（巨大な教師モデルの知識を小さな生徒モデルに継承）などがある。', detailed: `<h4>モデル圧縮 詳細解説</h4><p>高性能なディープラーニングモデルは、パラメータ数が膨大で計算量も多く、スマートフォンなどのリソースが限られたデバイスで動かすのは困難です。モデル圧縮は、精度をできるだけ維持しつつ、モデルを軽量化・高速化するための技術の総称です。</p><h4>G検定でのポイント</h4><p>ディープラーニングモデルをスマートフォンなどのエッジデバイスで動作させる（エッジAI）ために不可欠な技術群です。代表的な手法である「量子化」「枝刈り」「知識蒸留」の概要は押さえておきましょう。</p>` },
            
            // --- データサイエンス・統計 ---
            { term: 'EDA (探索的データ分析)', category: 'データサイエンス・統計', description: 'データセットを様々な角度から可視化・要約し、データの構造や特徴、パターン、外れ値などを把握するプロセス。<strong>【技術詳細】</strong>ヒストグラム、散布図、箱ひげ図などのグラフ作成や、平均、中央値、相関係数などの基本統計量の計算を行う。', detailed: `<h4>EDA 詳細解説</h4><p>本格的なモデル構築に入る前に、データと「対話」し、その性質を深く理解するための分析プロセスです。データの全体像を把握したり、異常な値（外れ値）や欠損値の存在を確認したり、変数間の関係性を探ったりします。</p><h4>G検定でのポイント</h4><p>機械学習モデルを構築する前の、非常に重要な準備段階です。データへの理解を深めることで、適切な前処理やモデル選択の方針を立てることができます。</p>` },
            { term: '特徴量エンジニアリング', category: 'データサイエンス・統計', description: '生のデータからモデルが学習しやすい特徴量を作成・選択・加工するプロセス。<strong>【技術詳細】</strong>ドメイン知識を活かして新しい特徴量を作成したり、カテゴリ変数をOne-Hotエンコーディングしたり、数値データを標準化・正規化したりする作業が含まれる。', detailed: `<h4>特徴量エンジニアリング 詳細解説</h4><p>手元にある生のデータから、モデルの予測精度を向上させるような、より本質的で有用な特徴量を作り出す作業全般を指します。例えば、日付データから「曜日」や「月末かどうか」という新しい特徴量を作ったり、複数の変数を組み合わせて新しい指標を作ったりします。</p><h4>G検定でのポイント</h4><p>モデルの性能を最も大きく左右すると言われることもある重要な工程です。「Garbage In, Garbage Out（ゴミを入れればゴミしか出てこない）」という言葉が示す通り、質の悪いデータをいくら高度なモデルに入れても良い結果は得られません。</p>` },
            { term: '欠損値処理', category: 'データサイエンス・統計', description: 'データセットに含まれる値がない（欠損している）部分に対処すること。<strong>【技術詳細】</strong>欠損している行や列を削除する、平均値や中央値で補完する、機械学習モデルで予測して補完するなどの手法がある。', detailed: `<h4>欠損値処理 詳細解説</h4><p>収集したデータには、入力ミスやシステムエラーなど様々な理由で値が入っていない「欠損値」が含まれることがよくあります。多くの機械学習アルゴリズムは欠損値を含むデータを扱えないため、何らかの方法で対処する必要があります。</p><h4>G検定でのポイント</h4><p>データ分析の前処理として必須の作業です。どのような手法で欠損値を処理したかが、後のモデルの性能に影響を与える可能性があります。</p>` },
            { term: 'データ拡張 (Data Augmentation)', category: 'データサイエンス・統計', description: '既存の訓練データを人工的に水増しする技術。過学習の抑制に有効。<strong>【活用例】</strong>画像データに対して、回転、反転、拡大・縮小、明るさの変更などの処理を加え、あたかも新しいデータであるかのように見せかけて学習させる。', detailed: `<h4>データ拡張 詳細解説</h4><p>特にディープラーニングでは大量の学習データが必要ですが、十分な量のデータを集めるのが難しい場合があります。データ拡張は、手持ちのデータに少し変化を加えることで、学習データのバリエーションを増やし、モデルの汎化性能を高めるテクニックです。</p><h4>G検定でのポイント</h4><p>特に画像認識の分野で、過学習を防ぎモデルの汎化性能を高めるための常套手段となっています。少ないデータからでも、より頑健なモデルを作成するのに役立ちます。</p>` },
            { term: '標準化と正規化', category: 'データサイエンス・統計', description: '複数の特徴量の尺度（スケール）を揃えるための前処理。<strong>【技術詳細】</strong>標準化は平均0、分散1に変換。正規化は最小値0、最大値1の範囲に変換。距離ベースの手法（SVM、k-NNなど）で特に重要。', detailed: `<h4>標準化と正規化 詳細解説</h4><p>データに含まれる特徴量（例：身長と体重）は、単位や尺度がバラバラです。尺度が大きい特徴量の影響が不当に大きくなってしまうのを防ぐため、すべての特徴量を同じような範囲の数値に変換する処理です。</p><h4>G検定でのポイント</h4><p>特徴量ごとに数値のスケールが大きく異なると、モデルの学習がうまくいかないことがあります。特に、距離を計算するアルゴリズム（k-NN、SVMなど）や、勾配降下法を用いる多くのモデルで効果的です。</p>` },
            { term: '混合行列 (Confusion Matrix)', category: 'データサイエンス・統計', description: '分類モデルの性能を評価するための表。予測が正解だったか不正解だったかを、クラスごとにまとめる。<strong>【技術詳細】</strong>True Positive (TP), False Positive (FP), True Negative (TN), False Negative (FN) の4つの値から構成される。', detailed: `<h4>混合行列 詳細解説</h4><p>混合行列は、2値分類などの分類モデルの性能を詳細に評価するための表です。モデルの予測結果と実際の正解クラスを比較し、どのように間違えたのかを一目で把握できます。</p><p>G検定では、この表の4つの要素を正確に理解することが必須です。（例：「犬」を陽性、「猫」を陰性とする）</p><ul><li><strong>真陽性 (True Positive, TP):</strong> 実際に「犬」の画像を「犬」と正しく予測できた数。</li><li><strong>偽陽性 (False Positive, FP):</strong> 実際は「猫」の画像を、間違って「犬」と予測してしまった数。（第一種の過誤）</li><li><strong>真陰性 (True Negative, TN):</strong> 実際に「猫」の画像を「猫」と正しく予測できた数。</li><li><strong>偽陰性 (False Negative, FN):</strong> 実際は「犬」の画像を、間違って「猫」と予測してしまった数。（第二種の過誤）</li></ul><h4>G検定でのポイント</h4><p>この4つの要素から、<strong>適合率(Precision)</strong>、<strong>再現率(Recall)</strong>、<strong>F値</strong>といった重要な評価指標が計算されます。単に正解率(Accuracy)を見るだけでは、特に不均衡データの場合にモデルの性能を正しく評価できないため、これらの指標がなぜ重要なのかを理解しておくことが大切です。</p>` },
            { term: '適合率 (Precision) と 再現率 (Recall)', category: 'データサイエンス・統計', description: '分類モデルの評価指標。<strong>【技術詳細】</strong>適合率=TP/(TP+FP)で「陽性と予測した中で、実際に陽性だった割合」。再現率=TP/(TP+FN)で「実際に陽性のものを見逃さずに予測できた割合」。両者はトレードオフの関係。', detailed: `<h4>適合率・再現率 詳細解説</h4><p>混合行列から計算される、分類モデルの性能指標です。</p><ul><li><strong>適合率 (Precision):</strong> モデルが「陽性」と予測したものの中で、実際に正解だったものの割合。誤報の少なさを示します。</li><li><strong>再現率 (Recall):</strong> 実際に「陽性」であるもの全体の中で、モデルが正しく「陽性」と予測できたものの割合。見逃しの少なさを示します。</li></ul><h4>G検定でのポイント</h4><p>どちらを重視すべきかは、タスクの目的によって異なります。例えば、迷惑メール判定では「通常メールを迷惑メールと誤判定しないこと」が重要なので適合率が重視されます。一方、病気の診断では「病気を見逃さないこと」が最優先なので再現率が重視されます。</p>` },
            { term: 'F値 (F-measure)', category: 'データサイエンス・統計', description: '適合率と再現率の調和平均。両方の指標をバランス良く評価する。<strong>【技術詳細】</strong><code>2 * (Precision * Recall) / (Precision + Recall)</code> で計算される。不均衡データ（陽性例が極端に少ないなど）の評価に適している。', detailed: `<h4>F値 詳細解説</h4><p>適合率と再現率はトレードオフの関係にあるため、片方を上げるともう一方が下がることがよくあります。F値は、この2つの指標のバランスを取った総合的な評価指標で、調和平均で計算されます。</p><h4>G検定でのポイント</h4><p>適合率と再現率がトレードオフの関係にあるため、両方をバランスよく評価したい場合に用いられる総合的な指標です。</p>` },
            { term: 'ROC曲線・AUC', category: 'データサイエンス・統計', description: '2値分類モデルの性能評価で用いられる指標。<strong>【技術詳細】</strong>ROC曲線は、分類の閾値を変化させたときの真陽性率（再現率）と偽陽性率の関係をプロットしたグラフ。AUCはその曲線下の面積で、1に近いほど高性能。', detailed: `<h4>ROC曲線・AUC 詳細解説</h4><p>2値分類モデルの性能を可視化するためのグラフと、その性能を一つの数値で表す指標です。</p><ul><li><strong>ROC曲線:</strong> 横軸に偽陽性率、縦軸に真陽性率（再現率）をとり、分類の閾値を様々に変化させたときの点の軌跡を描いた曲線です。</li><li><strong>AUC (Area Under the Curve):</strong> ROC曲線の下側の面積のこと。この面積が大きいほど、モデルの性能が良いとされます。</li></ul><h4>G検定でのポイント</h4><p>AUCは、モデルがどれだけ陽性クラスと陰性クラスをうまく分離できているかを示す指標と解釈できます。0.5はランダムな予測と同じで、1.0が完璧なモデルを意味します。</p>` },
            { term: 'バイアスとバリアンス', category: 'データサイエンス・統計', description: 'モデルの予測誤差を構成する2つの要素。<strong>【技術詳細】</strong>バイアスはモデルの予測の偏り（単純すぎてデータにフィットしない）。バリアンスはデータのばらつきによる予測の不安定さ（複雑すぎてデータに過剰反応する）。両者はトレードオフの関係にある。', detailed: `<h4>バイアスとバリアンス 詳細解説</h4><p>モデルの予測誤差は、主にバイアス、バリアンス、そしてノイズの3つに分解できるとされています。</p><ul><li><strong>バイアス:</strong> モデルの予測が、真の値からどれだけ体系的にずれているか。バイアスが高いと学習不足（Underfitting）の状態。</li><li><strong>バリアンス:</strong> 学習データが少し変わっただけで、モデルの予測がどれだけ大きく変動するか。バリアンスが高いと過学習（Overfitting）の状態。</li></ul><h4>G検定でのポイント</h4><p>両者のトレードオフの関係性が重要です。モデルが複雑になるほどバイアスは低下しますが、バリアンスは増加（過学習のリスク）します。逆にモデルが単純すぎるとバリアンスは低下しますが、バイアスは増加（学習不足）します。このバランスを取ることが良いモデル作成の鍵です。</p>` },
            { term: 'p値 (p-value)', category: 'データサイエンス・統計', description: '統計的仮説検定で、帰無仮説のもとで観測された結果以上に極端な結果が得られる確率。<strong>【技術詳細】</strong>慣習的にp値が0.05などの有意水準より小さい場合、帰無仮説は棄却され、対立仮説が採択される。', detailed: `<h4>p値 詳細解説</h4><p>統計的な仮説検定において、「帰無仮説（差がない、効果がないなどの仮説）」が正しいと仮定したときに、観測されたデータか、それ以上に極端なデータが得られる確率を指します。この値が小さいほど、「それは偶然では起こりにくい」と判断できます。</p><h4>G検定でのポイント</h4><p>p値が小さいことは統計的に「偶然とは考えにくい」ことを示しますが、それが「効果が大きい」ことや「因果関係がある」ことを直接意味するわけではない点に注意が必要です。</p>` },
            { term: '不均衡データ (Imbalanced Data)', category: 'データサイエンス・統計', description: '分類問題で、クラス間のデータ数に大きな偏りがあるデータセット。<strong>【技術詳細】</strong>そのまま学習すると多数派クラスに偏ったモデルになりやすい。対策として、<code>オーバーサンプリング</code>(SMOTEなど)や<code>アンダーサンプリング</code>がある。', detailed: `<h4>不均衡データ 詳細解説</h4><p>分類タスクにおいて、クラスごとのデータ数が極端に異なるデータを指します。例えば、クレジットカードの不正利用検知では、正常な取引データが99.9%、不正な取引データが0.1%といったケースが考えられます。</p><h4>G検定でのポイント</h4><p>クレジットカードの不正利用検知や、工場の不良品検知など、現実世界の多くの問題は不均衡データです。そのため、適切な対処法（サンプリング手法の適用や、評価指標としてAccuracyではなくF値やAUCを用いるなど）を知っていることが重要です。</p>` },

            // --- ハードウェア・インフラ ---
            { term: 'GPU (Graphics Processing Unit)', category: 'ハードウェア・インフラ', description: '元々は画像処理用のプロセッサだが、単純な計算を並列で大量にこなす能力に長けているため、ディープラーニングの行列演算で広く利用される。NVIDIA社が有名。', detailed: `<h4>GPU 詳細解説</h4><p>GPUは、元々コンピュータグラフィックスの描画処理を高速化するために開発されたプロセッサです。単純な計算を大量に並列実行する能力に非常に長けています。</p><p>ディープラーニングでは、ニューラルネットワークの学習時に膨大な量の行列演算（積和演算）が発生します。この行列演算は、まさにGPUが得意とする単純な並列計算の塊です。そのため、CPUで学習させるよりも劇的に高速に処理を終えることができます。</p><h4>G検定でのポイント</h4><p>「ディープラーニングの発展はGPUの進化なくしてはあり得なかった」という点は非常に重要です。特にNVIDIA社が開発した<code>CUDA</code>という並列コンピューティングプラットフォームにより、GPUを汎用的な計算に利用する<code>GPGPU</code>という技術が普及し、AI研究が加速しました。この背景を理解しておきましょう。</p>` },
            { term: 'TPU (Tensor Processing Unit)', category: 'ハードウェア・インフラ', description: 'Googleがディープラーニング専用に開発したプロセッサ。行列演算に特化しており、GPUよりもさらに高速・高効率な処理が可能。Google Cloudなどで利用できる。', detailed: `<h4>TPU 詳細解説</h4><p>Googleが自社のディープラーニングフレームワークTensorFlowでの処理に最適化された専用プロセッサ（ASIC）として開発しました。特に、大量の行列演算を非常に高い電力効率で実行できるように設計されています。</p><h4>G検定でのポイント</h4><p>Googleが自社のサービス（翻訳、検索など）とクラウドサービスのために開発した専用ハードウェアです。特に推論処理において高い電力効率を誇ります。</p>` },
            { term: 'FPGA (Field-Programmable Gate Array)', category: 'ハードウェア・インフラ', description: '製造後に購入者が回路構成をプログラムできる集積回路。特定の処理に特化した回路を組むことで、低遅延・低消費電力を実現できる。エッジAIなどで利用される。', detailed: `<h4>FPGA 詳細解説</h4><p>用途に応じて後から回路設計を書き換えられる半導体チップです。特定のタスクに特化した回路を実装することで、汎用プロセッサであるCPUやGPUよりも低消費電力・低遅延な処理を実現できます。</p><h4>G検定でのポイント</h4><p>GPUやTPUほど汎用的ではありませんが、特定のタスクに特化した回路を設計することで、非常に低遅延な処理が可能です。そのため、リアルタイム性が求められるエッジデバイスでの推論などに利用されます。</p>` },
            { term: 'クラウドコンピューティング', category: 'ハードウェア・インフラ', description: 'インターネット経由で、サーバー、ストレージ、データベース、AIモデルなどのコンピューティングサービスを利用すること。<strong>【活用例】</strong>AWS、Google Cloud(GCP)、Microsoft Azureが3大クラウドとして知られ、高性能なGPUインスタンスやAI開発プラットフォームを提供している。', detailed: `<h4>クラウドコンピューティング 詳細解説</h4><p>ハードウェアやソフトウェアを自社で保有するのではなく、インターネット上のサービスとして利用する形態です。AI開発においては、高性能なGPUサーバーを必要な時間だけレンタルしたり、学習済みモデルを利用できるAPIサービスを使ったりすることが一般的です。</p><h4>G検定でのポイント</h4><p>自前で高価な計算機サーバーを保有することなく、必要な時に必要なだけ計算リソースを利用できるため、AI開発のハードルを大きく下げました。代表的なサービス（AWS, GCP, Azure）と、それぞれが提供するAI関連サービス（Amazon SageMaker, Google Vertex AI, Azure Machine Learningなど）の名前は知っておくと良いでしょう。</p>` },
            { term: 'コンテナ技術', category: 'ハードウェア・インフラ', description: 'アプリケーションを、その実行に必要なライブラリや設定などと一緒にパッケージ化する技術。<strong>【技術詳細】</strong><code>Docker</code>が代表的。どこでも同じ環境を再現できるため、開発から本番環境への移行がスムーズになる。', detailed: `<h4>コンテナ技術 詳細解説</h4><p>OSレベルの仮想化技術の一種で、アプリケーションをその実行環境（ライブラリ、依存パッケージなど）ごと「コンテナ」として隔離します。これにより、「自分のパソコンでは動いたのに、サーバー上では動かない」といった環境差異の問題を解消できます。</p><h4>G検定でのポイント</h4><p>AIモデルを開発した環境と、実際に運用する環境の違いによる問題を解消できるため、MLOpsにおいて重要な役割を果たします。Dockerが事実上の標準となっています。</p>` },
            { term: 'Kubernetes', category: 'ハードウェア・インフラ', description: 'コンテナ化されたアプリケーションのデプロイ、スケーリング、管理を自動化するためのオープンソースシステム。コンテナオーケストレーションツールとも呼ばれる。', detailed: `<h4>Kubernetes 詳細解説</h4><p>Dockerなどで作成した多数のコンテナを、複数のサーバーにまたがって効率的に管理・運用するためのツールです。アクセスの増減に応じてコンテナの数を自動で調整したり、障害が発生したコンテナを自動で再起動したりする機能などを持ちます。</p><h4>G検定でのポイント</h4><p>多数のコンテナを協調させて、大規模なサービスを安定運用するための管理ツールです。Googleが開発した技術がオープンソース化されたものです。</p>` },
            { term: 'MLOps', category: 'ハードウェア・インフラ', description: '機械学習(ML)と運用(Operations)を組み合わせた造語。機械学習モデルの開発から運用、再学習までのライフサイクルを効率的に管理・自動化するためのプラクティス。', detailed: `<h4>MLOps 詳細解説</h4><p>ソフトウェア開発におけるDevOpsの考え方を、機械学習に応用したものです。AIモデルを一度開発して終わりにするのではなく、本番環境での性能を監視し、新しいデータを使って継続的に再学習・デプロイしていくサイクルを自動化・効率化することを目指します。</p><h4>G検定でのポイント</h4><p>AIモデルは一度作って終わりではなく、継続的に性能を監視し、新しいデータで再学習させて改善していく必要があります。MLOpsは、そのための仕組みや文化全体を指す言葉として重要です。</p>` },
            
            // --- 法律・倫理 ---
            { term: '個人情報保護法', category: '法律・倫理', description: '個人の権利利益を保護することを目的とした法律。<strong>【具体例】</strong>AIチャットボットに顧客が入力した氏名や住所を、本人の同意なくマーケティングに利用することは違法となる。', detailed: `<h4>個人情報保護法 詳細解説</h4><p>個人情報を取り扱う事業者が遵守すべきルールを定めた法律です。「個人情報」「仮名加工情報」「匿名加工情報」といった情報の種類によって、遵守すべき義務が異なります。AI開発において、学習データとして個人情報を含むデータを利用する際には、適切な取り扱いが求められます。</p><h4>G検定でのポイント</h4><p>氏名や住所だけでなく、他の情報と組み合わせることで個人を特定できる情報（例：購買履歴と会員ID）も個人情報に含まれる場合があります。また、本人の同意なく個人情報を第三者に提供することは原則禁止されています。</p>` },
            { term: '著作権法', category: '法律・倫理', description: '著作物と著作者の権利を保護する法律。<strong>【具体例】</strong>インターネット上のイラストを無断で大量に学習データとして利用し、作風を模倣した画像を生成するAIサービスは、著作権侵害となる可能性がある。', detailed: `<h4>著作権法 詳細解説</h4><p>小説、音楽、絵画、プログラムなどの「著作物」を創作した者（著作者）に与えられる権利を保護する法律です。AIとの関係では、①AIの学習データとして著作物を利用することの可否、②AIが生成したコンテンツの著作権は誰に帰属するのか、という2点が大きな論点となります。</p><h4>G検定でのポイント</h4><p>AIの学習データとしてWeb上のコンテンツを利用する場合や、画像生成AIの出力など、AIと著作権の問題はG検定でも頻出のトピックです。思想や感情の創作的な表現が保護対象であり、単なるデータは対象外であるという基本を理解しておきましょう。</p>` },
            { term: 'GDPR (一般データ保護規則)', category: '法律・倫理', description: 'EUにおける個人のデータ保護とプライバシーに関する包括的な法律。<strong>【具体例】</strong>日本の企業がEU居住者向けにサービスを提供する場合、Cookie利用の同意を明確に取得したり、ユーザーからのデータ削除要求に応じたりする必要がある。', detailed: `<h4>GDPR 詳細解説</h4><p>EU（欧州連合）における、個人データ保護のための包括的な法的枠組みです。非常に厳格なルールを定めており、違反した場合には多額の制裁金が課される可能性があります。プロファイリングのような自動化された処理に対して「説明を受ける権利」などを定めている点も特徴です。</p><h4>G検定でのポイント</h4><p>EU域内の個人データを扱うすべての事業者が対象となるため、日本の企業も無関係ではありません。「忘れられる権利」や「データポータビリティの権利」など、個人の権利を強く保護している点が特徴です。</p>` },
            { term: 'AI開発原則', category: '法律・倫理', description: '内閣府が示した、AI開発者が遵守すべき原則。「人間の尊厳」「多様性・公平性」「プライバシーの確保」「セキュリティ」「透明性」などが含まれる。', detailed: `<h4>AI開発原則 詳細解説</h4><p>AIが社会に受け入れられ、適切に利用されるために、開発者や提供者がどのような点に配慮すべきかを示した倫理的な指針です。多くの国や組織が同様の原則を発表しており、内容は共通する部分が多いです。</p><h4>G検定でのポイント</h4><p>これらは法的な拘束力を持つものではありませんが（ソフトロー）、AIを開発・利用する上で遵守すべき倫理的な指針として、国内外の多くの組織が同様の原則を公表しています。</p>` },
            { term: '説明可能なAI (XAI)', category: '法律・倫理', description: 'AIの判断根拠を人間が理解・解釈できるようにするための技術。<strong>【技術詳細】</strong>判断に寄与した特徴量を可視化するLIMEやSHAP、CNNの判断根拠を可視化するGrad-CAMなどの手法がある。', detailed: `<h4>なぜ重要か？</h4><p>AIの判断が「ブラックボックス」のままだと、以下のような問題が生じます。</p><ul><li><strong>信頼性の欠如:</strong> なぜその結論に至ったのか分からないと、ユーザーはAIの判断を信頼できません。特に医療診断や融資審査など、重要な意思決定で問題となります。</li><li><strong>公平性の担保:</strong> AIが意図せず不公平なバイアス（偏見）に基づいて判断していたとしても、それを発見・修正することが困難です。</li><li><strong>安全性の確保:</strong> 自動運転車がなぜ特定の操作をしたのか分からなければ、事故原因の究明や再発防止ができません。</li></ul><h4>G検定でのポイント</h4><p>GDPR（EU一般データ保護規則）では「説明を受ける権利」が明記されるなど、XAIは法規制や社会的な要請としても重要度が増しています。具体的な手法として、モデル全体の判断傾向を説明する<code>LIME</code>や<code>SHAP</code>、CNNが画像のどこに注目したかを可視化する<code>Grad-CAM</code>などの名称も覚えておくと良いでしょう。</p>` },
            { term: 'アルゴリズムの公平性 / バイアス', category: '法律・倫理', description: 'AIモデルが、特定の属性に基づいて不公平な判断を下してしまう問題。<strong>【具体例】</strong>過去の採用データに男性が多いという偏りがあった場合、それを学習したAIが男性を優先的に採用してしまう「ジェンダーバイアス」。', detailed: `<h4>アルゴリズムの公平性 / バイアス 詳細解説</h4><p>AIは、学習に用いたデータに含まれる偏見（バイアス）を学習し、増幅させてしまうことがあります。例えば、過去のデータに基づいて採用AIを作った場合、特定の性別や人種を不当に有利／不利に扱ってしまう可能性があります。これは、AI倫理における非常に重要な課題です。</p><h4>G検定でのポイント</h4><p>学習データに含まれる社会的な偏見をAIが増幅・再生産してしまうリスクが問題視されています。採用、融資、司法など、社会的に重要な分野でのAI利用において特に重要な課題です。</p>` },
            { term: 'フレーム問題', category: '法律・倫理', description: 'AIにおける重要な哲学的問題。「ある行動を実行する際に、考慮すべき有限の事柄と、無関係で考慮しなくてよい事柄を、どうやって限定するのか」という問題。', detailed: `<h4>フレーム問題 詳細解説</h4><p>ロボットが「部屋の中にある時限爆弾を部屋の外に出す」というタスクを実行するシナリオで有名です。ロボットは、行動によって「変化すること」だけでなく、膨大な「変化しないこと」（例：壁の色は変わらない、天井は落ちてこない）まで考慮し始めてしまい、計算が終わらず行動不能に陥ります。</p><h4>G検定でのポイント</h4><p>記号的AIが直面した根源的な困難さを示す問題です。「人間は常識によって無関係なことを自然に無視しているが、コンピュータにそれをどう教えるか」という問題とも言えます。</p>` },
            { term: 'シンボルグラウンディング問題', category: '法律・倫理', description: 'AIが扱う記号（シンボル）が、実世界の意味とどのように結びついているのか（接地しているのか）という問題。記号処理だけでは真の知能とは言えないという批判。', detailed: `<h4>シンボルグラウンディング問題 詳細解説</h4><p>コンピュータは「犬」という単語を記号として処理できますが、その記号が、現実世界にいる温かくて毛むくじゃらの動物としての「犬」の実体と結びついているわけではありません。この記号と実体の結びつき（接地＝グラウンディング）がなければ、AIは本当の意味で世界を理解しているとは言えない、という哲学的な問題です。</p><h4>G検定でのポイント</h4><p>「中国語の部屋」の思考実験とも関連する哲学的な問題です。例えば、AIが「犬」という記号（単語）を扱えても、それが実世界の「犬」という存在と結びついていなければ、真に理解しているとは言えない、という議論です。</p>` },
            { term: 'ディープフェイク', category: '法律・倫理', description: 'ディープラーニングを用いて、人物の顔や声を本物そっくりに合成した偽の動画や音声。<strong>【技術詳細】</strong>主にGANの技術が利用されている。', detailed: `<h4>ディープフェイク 詳細解説</h4><p>GAN（敵対的生成ネットワーク）などのディープラーニング技術を用いて、非常に精巧な偽の動画や音声を作成する技術です。有名人や政治家が言ってもいないことを言っているかのような動画を作成でき、社会的な混乱や名誉毀損に繋がるリスクが懸念されています。</p><h4>G検定でのポイント</h4><p>フェイクニュースの拡散や、個人の名誉毀損など、社会的な混乱を招くリスクが懸念されています。GAN（敵対的生成ネットワーク）の技術が悪用された例として頻出します。</p>` },
            { term: 'トロリー問題', category: '法律・倫理', description: '倫理学における思考実験。<strong>【具体例】</strong>自動運転車が事故を避けられない状況で、「歩行者一人を犠牲にするか、乗員が犠牲になるか」といったAIの倫理的な意思決定の難しさを示す例として挙げられる。', detailed: `<h4>トロリー問題 詳細解説</h4><p>暴走するトロッコの進路を切り替えることで、5人を助ける代わりに、切り替え先の線路にいる1人を犠牲にすることは許されるか？という倫理学の有名な思考実験です。AI、特に自動運転車が事故を避けられない状況で、どのような判断を下すべきかという問題に置き換えられて議論されます。</p><h4>G検定でのポイント</h4><p>AI、特に自動運転のような自律システムに、倫理的な判断をどう実装するかという問題の難しさを示す例として挙げられます。どの選択肢が「正解」かは人間でも結論が出ないため、AIにそれをプログラムすることの困難さを示唆しています。</p>` },
            
            // --- 応用分野 ---
            { term: '自然言語処理 (NLP)', category: '応用分野', description: '人間が日常的に使う言葉（自然言語）をコンピュータが処理・理解するための技術分野。<strong>【活用例】</strong>SiriやGoogleアシスタント、機械翻訳のDeepL、文法チェックツールのGrammarlyなど。', detailed: `<h4>自然言語処理 詳細解説</h4><p>人間が日常的に使う言葉（自然言語）をコンピュータに処理させる技術全般を指します。文章の自動要約、機械翻訳、対話システム（チャットボット）、感情分析など、非常に幅広い応用があります。</p><h4>G検定でのポイント</h4><p>形態素解析、構文解析、意味解析といった伝統的な手法から、Transformerベースの大規模言語モデルまで、幅広い技術が含まれます。近年のAIの進化を最も象徴する分野の一つです。</p>` },
            { term: '画像認識', category: '応用分野', description: '画像や動画の中から、特定の物体、人物、風景などを識別・検出する技術。<strong>【活用例】</strong>Facebookの写真の自動タグ付け、空港の顔認証ゲート、自動車のナンバープレート読み取りシステム。', detailed: `<h4>画像認識 詳細解説</h4><p>コンピュータが画像の内容を理解するための技術です。単に画像全体が何かを分類するだけでなく、画像内のどこに何があるかを検出したり（物体検出）、領域をピクセル単位で塗り分けたり（セグメンテーション）するタスクも含まれます。</p><h4>G検定でのポイント</h4><p>CNNの登場によって精度が飛躍的に向上しました。「分類」「物体検出」「セグメンテーション」など、タスクによって目的が異なることを理解しましょう。ILSVRCという画像認識コンペが技術発展の大きなマイルストーンとなりました。</p>` },
            { term: '音声認識', category: '応用分野', description: '人間が発する音声・話し言葉をコンピュータが解析し、テキストデータに変換する技術。<strong>【活用例】</strong>スマートスピーカー（Amazon Echo）、Zoomの自動文字起こし機能、コールセンターでの通話内容のテキスト化。', detailed: `<h4>音声認識 詳細解説</h4><p>人間が発した音声を、コンピュータが処理できるテキストデータに変換する技術です。スマートスピーカーへの命令や、会議の議事録作成、スマートフォンの音声入力など、私たちの身近なところで広く使われています。</p><h4>G検定でのポイント</h4><p>音響モデル（音声を音素に変換）と、言語モデル（音素の並びを単語や文章に変換）を組み合わせて実現されます。ディープラーニングの導入により、こちらも精度が大幅に向上しました。</p>` },
            { term: '推薦システム (レコメンデーション)', category: '応用分野', description: 'ユーザーの履歴などから好みに合いそうな項目を推薦するシステム。<strong>【技術詳細】</strong>ユーザーの行動履歴から推薦する「協調フィルタリング」、アイテムの類似性から推薦する「コンテンツベースフィルタリング」などがある。', detailed: `<h4>推薦システム 詳細解説</h4><p>ユーザーの過去の購買履歴や閲覧履歴、評価などを分析し、そのユーザーが興味を持ちそうな商品やコンテンツを提示するシステムです。ECサイトや動画配信サービスなどで広く利用されています。</p><h4>G検定でのポイント</h4><p>ECサイトや動画配信サービスなど、多くのWebサービスで顧客体験の向上と売上増加のために利用されています。「協調フィルタリング」は「あなたと似た興味を持つ他のユーザー」の行動に基づいて推薦する手法として重要です。</p>` },
            { term: 'エッジAI', category: '応用分野', description: 'クラウドではなく、端末（エッジ）側でAIの推論処理を行う技術。<strong>【技術詳細】</strong>モデルの軽量化技術（量子化、プルーニングなど）が重要となる。通信遅延の低減やプライバシー保護の観点で注目されている。', detailed: `<h4>エッジAI 詳細解説</h4><p>AIの処理（特に推論）を、クラウド上の巨大なサーバーではなく、スマートフォンやカメラ、自動車などのユーザーの手元にあるデバイス（エッジデバイス）上で行う技術です。</p><h4>G検定でのポイント</h4><p>すべてのデータをクラウドに送る必要がないため、①通信遅延が少ない（リアルタイム性が高い）、②オフラインでも動作する、③プライバシー保護に繋がる、といったメリットがあります。スマートフォンや自動車、監視カメラなどがエッジデバイスの例です。</p>` },
            { term: 'DX (デジタルトランスフォーメーション)', category: '応用分野', description: 'AIやIoTなどのデジタル技術を活用して、ビジネスモデルや業務を変革すること。<strong>【具体例】</strong>熟練工の技術をAIに学習させて品質管理を自動化する、顧客データを分析して一人ひとりに最適なサービスを提供するなど。', detailed: `<h4>DX 詳細解説</h4><p>経済産業省の定義によれば、「企業がビジネス環境の激しい変化に対応し、データとデジタル技術を活用して、顧客や社会のニーズを基に、製品やサービス、ビジネスモデルを変革するとともに、業務そのものや、組織、プロセス、企業文化・風土を変革し、競争上の優位性を確立すること」です。</p><h4>G検定でのポイント</h4><p>単なるデジタル化（デジタイゼーション）や業務効率化（デジタライゼーション）に留まらず、AIなどのデジタル技術を前提として、ビジネスモデルそのものを変革し、新たな価値を創出することがDXの本質です。</p>` },
            { term: 'AGI (汎用人工知能)', category: '応用分野', description: '特定のタスクに特化した現在のAI（特化型AI）とは異なり、人間のように様々なタスクを柔軟にこなし、自ら学習できるAIのこと。まだ実現には至っていない。', detailed: `<h4>AGI 詳細解説</h4><p>Artificial General Intelligenceの略。特定の目的に特化して開発された現在のAI（特化型AI）と対比される概念です。人間のように、未知の問題に対しても、自ら学習し、常識を働かせて柔軟に対応できるAIを目指す研究分野ですが、実現の見通しは立っていません。</p><h4>G検定でのポイント</h4><p>現在主流のAIは、特定のタスクに特化した「特化型AI（Narrow AI）」です。AGIは、まだSFの世界の話ですが、AI研究の究極的な目標の一つとして議論されます。</p>` },
            { term: 'コグニティブ・コンピューティング', category: '応用分野', description: '人間のように経験から学習し、文脈を理解し、対話できるコンピュータシステム。IBMの「Watson」が代表例。', detailed: `<h4>コグニティブ・コンピューティング 詳細解説</h4><p>人間の思考プロセスを模倣し、大量の非構造化データ（自然言語、画像、音声など）から文脈を理解し、仮説を立て、学習を通じて賢くなっていくコンピュータシステムを指す言葉です。IBM社が提唱する概念で、同社のAI「Watson」がその具体例として有名です。</p><h4>G検定でのポイント</h4><p>IBMが提唱している概念で、同社のAI「Watson」がその代表例です。データから自律的に学習し、人間と自然な対話を通じて意思決定を支援することを目的としています。</p>` },
            { term: 'RPA (Robotic Process Automation)', category: '応用分野', description: 'ソフトウェアロボットを用いて、PC上の定型的な事務作業を自動化する技術。AIと組み合わせることで、より高度で非定型な業務の自動化も可能になる。', detailed: `<h4>RPA 詳細解説</h4><p>主にPC上で行われる、ルールが決まっている定型的なクリックやキーボード入力などの操作を、ソフトウェアのロボットが代行して自動化する技術です。「仮想知的労働者（デジタルレイバー）」とも呼ばれます。</p><h4>G検定でのポイント</h4><p>主にルールベースで動作する定型業務の自動化ツールです。AI、特にOCR（光学的文字認識）や自然言語処理と組み合わせることで、請求書の読み取りなど、より高度な業務の自動化が可能になる「インテリジェント・オートメーション」という概念も重要です。</p>` }
        ];

        const searchInput = document.getElementById('searchInput');
        const categoryFilters = document.getElementById('categoryFilters');
        const termList = document.getElementById('termList');
        const noResults = document.getElementById('noResults');
        const explanationModal = document.getElementById('explanationModal');
        const modalTitle = document.getElementById('modalTitle');
        const closeModalBtn = document.getElementById('closeModalBtn');
        const detailedExplanationEl = document.getElementById('detailedExplanation');

        let currentCategory = 'all';

        // 用語カードをレンダリングする関数
        const renderTerms = (filteredTerms) => {
            termList.innerHTML = '';
            if (filteredTerms.length === 0) {
                noResults.classList.remove('hidden');
            } else {
                noResults.classList.add('hidden');
            }

            // 用語をあいうえお順でソート
            filteredTerms.sort((a, b) => a.term.localeCompare(b.term, 'ja'));

            filteredTerms.forEach(term => {
                const card = document.createElement('div');
                card.className = 'bg-gray-800 rounded-lg shadow-lg p-6 transition-all duration-300 hover:shadow-cyan-500/20 hover:-translate-y-1 flex flex-col relative';
                
                const categoryColor = {
                    '歴史・人物': 'bg-rose-500/20 text-rose-300',
                    '機械学習': 'bg-amber-500/20 text-amber-300',
                    'ディープラーニング': 'bg-cyan-500/20 text-cyan-300',
                    'データサイエンス・統計': 'bg-lime-500/20 text-lime-300',
                    'ハードウェア・インフラ': 'bg-teal-500/20 text-teal-300',
                    '法律・倫理': 'bg-violet-500/20 text-violet-300',
                    '応用分野': 'bg-emerald-500/20 text-emerald-300',
                };

                // Add the detailed explanation directly into the card's HTML
                card.innerHTML = `
                    <div class="flex justify-between items-start mb-2">
                        <h3 class="text-xl font-bold text-gray-100">${term.term}</h3>
                        <span class="text-xs font-semibold px-2.5 py-0.5 rounded-full flex-shrink-0 ml-2 ${categoryColor[term.category] || 'bg-gray-700'}">${term.category}</span>
                    </div>
                    <div class="text-gray-400 font-light leading-relaxed flex-grow term-description">
                        <p>${term.description}</p>
                        <div class="mt-4 detailed-explanation">${detailedExplanations[term.term]}</div>
                    </div>
                `;
                termList.appendChild(card);
            });
        };

        // フィルタリングとレンダリングを実行する関数
        const filterAndRender = () => {
            const searchTerm = searchInput.value.toLowerCase();
            
            let filteredTerms = termsData.filter(term => {
                const inCategory = currentCategory === 'all' || term.category === currentCategory;
                // Update search to include detailed explanation text
                const inSearch = term.term.toLowerCase().includes(searchTerm) || 
                                 term.description.toLowerCase().includes(searchTerm) ||
                                 detailedExplanations[term.term].toLowerCase().includes(searchTerm);
                return inCategory && inSearch;
            });
            
            renderTerms(filteredTerms);
        };

        // イベントリスナー
        searchInput.addEventListener('input', filterAndRender);

        categoryFilters.addEventListener('click', (e) => {
            if (e.target.tagName === 'BUTTON') {
                document.querySelector('.filter-btn.active').classList.remove('active');
                e.target.classList.add('active');
                currentCategory = e.target.dataset.category;
                filterAndRender();
            }
        });

        // カテゴリボタンのスタイリング
        const buttons = categoryFilters.querySelectorAll('.filter-btn');
        buttons.forEach(button => {
            button.classList.add('px-4', 'py-2', 'text-sm', 'font-medium', 'text-gray-300', 'bg-gray-800', 'rounded-full', 'hover:bg-gray-700', 'transition-colors', 'whitespace-nowrap');
            if (button.classList.contains('active')) {
                button.classList.add('!bg-cyan-600', '!text-white');
            }
        });

        // 初期表示
        filterAndRender();

        // アクティブなボタンのスタイルを上書きするためのCSSを追加
        const style = document.createElement('style');
        style.textContent = `
            .filter-btn.active {
                background-color: #0891b2 !important; /* Tailwindのcyan-600 */
                color: white !important;
                box-shadow: 0 0 10px 2px rgba(14, 165, 233, 0.4); /* Tailwindのcyan-500/40 */
            }
        `;
        document.head.appendChild(style);

    </script>
</body>
</html>
